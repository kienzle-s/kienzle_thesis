{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPjCb941iF0r"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLW_I8sViF0s"
      },
      "source": [
        "## Logistic Regression with 7 Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6ucNOVpiF0t",
        "outputId": "800149e5-1ca9-43cd-832d-8a2e3723aceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7214 entries, 0 to 7213\n",
            "Data columns (total 53 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       7214 non-null   int64  \n",
            " 1   name                     7214 non-null   object \n",
            " 2   first                    7214 non-null   object \n",
            " 3   last                     7214 non-null   object \n",
            " 4   compas_screening_date    7214 non-null   object \n",
            " 5   sex                      7214 non-null   object \n",
            " 6   dob                      7214 non-null   object \n",
            " 7   age                      7214 non-null   int64  \n",
            " 8   age_cat                  7214 non-null   object \n",
            " 9   race                     7214 non-null   object \n",
            " 10  juv_fel_count            7214 non-null   int64  \n",
            " 11  decile_score             7214 non-null   int64  \n",
            " 12  juv_misd_count           7214 non-null   int64  \n",
            " 13  juv_other_count          7214 non-null   int64  \n",
            " 14  priors_count             7214 non-null   int64  \n",
            " 15  days_b_screening_arrest  6907 non-null   float64\n",
            " 16  c_jail_in                6907 non-null   object \n",
            " 17  c_jail_out               6907 non-null   object \n",
            " 18  c_case_number            7192 non-null   object \n",
            " 19  c_offense_date           6055 non-null   object \n",
            " 20  c_arrest_date            1137 non-null   object \n",
            " 21  c_days_from_compas       7192 non-null   float64\n",
            " 22  c_charge_degree          7214 non-null   object \n",
            " 23  c_charge_desc            7185 non-null   object \n",
            " 24  is_recid                 7214 non-null   int64  \n",
            " 25  r_case_number            3471 non-null   object \n",
            " 26  r_charge_degree          3471 non-null   object \n",
            " 27  r_days_from_arrest       2316 non-null   float64\n",
            " 28  r_offense_date           3471 non-null   object \n",
            " 29  r_charge_desc            3413 non-null   object \n",
            " 30  r_jail_in                2316 non-null   object \n",
            " 31  r_jail_out               2316 non-null   object \n",
            " 32  violent_recid            0 non-null      float64\n",
            " 33  is_violent_recid         7214 non-null   int64  \n",
            " 34  vr_case_number           819 non-null    object \n",
            " 35  vr_charge_degree         819 non-null    object \n",
            " 36  vr_offense_date          819 non-null    object \n",
            " 37  vr_charge_desc           819 non-null    object \n",
            " 38  type_of_assessment       7214 non-null   object \n",
            " 39  decile_score.1           7214 non-null   int64  \n",
            " 40  score_text               7214 non-null   object \n",
            " 41  screening_date           7214 non-null   object \n",
            " 42  v_type_of_assessment     7214 non-null   object \n",
            " 43  v_decile_score           7214 non-null   int64  \n",
            " 44  v_score_text             7214 non-null   object \n",
            " 45  v_screening_date         7214 non-null   object \n",
            " 46  in_custody               6978 non-null   object \n",
            " 47  out_custody              6978 non-null   object \n",
            " 48  priors_count.1           7214 non-null   int64  \n",
            " 49  start                    7214 non-null   int64  \n",
            " 50  end                      7214 non-null   int64  \n",
            " 51  event                    7214 non-null   int64  \n",
            " 52  two_year_recid           7214 non-null   int64  \n",
            "dtypes: float64(4), int64(16), object(33)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ],
      "source": [
        "# loading data and general information\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_compas = pd.read_csv('compas-scores-two-years.csv')\n",
        "\n",
        "df_compas.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "4LYxD9LoiF0u",
        "outputId": "28473b5d-3b43-4d54-e7b3-a1b380372349"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>first</th>\n",
              "      <th>last</th>\n",
              "      <th>compas_screening_date</th>\n",
              "      <th>sex</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>race</th>\n",
              "      <th>...</th>\n",
              "      <th>v_decile_score</th>\n",
              "      <th>v_score_text</th>\n",
              "      <th>v_screening_date</th>\n",
              "      <th>in_custody</th>\n",
              "      <th>out_custody</th>\n",
              "      <th>priors_count.1</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>event</th>\n",
              "      <th>two_year_recid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>miguel hernandez</td>\n",
              "      <td>miguel</td>\n",
              "      <td>hernandez</td>\n",
              "      <td>2013-08-14</td>\n",
              "      <td>Male</td>\n",
              "      <td>1947-04-18</td>\n",
              "      <td>69</td>\n",
              "      <td>Greater than 45</td>\n",
              "      <td>Other</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-08-14</td>\n",
              "      <td>2014-07-07</td>\n",
              "      <td>2014-07-14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>327</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>kevon dixon</td>\n",
              "      <td>kevon</td>\n",
              "      <td>dixon</td>\n",
              "      <td>2013-01-27</td>\n",
              "      <td>Male</td>\n",
              "      <td>1982-01-22</td>\n",
              "      <td>34</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-01-27</td>\n",
              "      <td>2013-01-26</td>\n",
              "      <td>2013-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>ed philo</td>\n",
              "      <td>ed</td>\n",
              "      <td>philo</td>\n",
              "      <td>2013-04-14</td>\n",
              "      <td>Male</td>\n",
              "      <td>1991-05-14</td>\n",
              "      <td>24</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-04-14</td>\n",
              "      <td>2013-06-16</td>\n",
              "      <td>2013-06-16</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>marcu brown</td>\n",
              "      <td>marcu</td>\n",
              "      <td>brown</td>\n",
              "      <td>2013-01-13</td>\n",
              "      <td>Male</td>\n",
              "      <td>1993-01-21</td>\n",
              "      <td>23</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2013-01-13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1174</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>bouthy pierrelouis</td>\n",
              "      <td>bouthy</td>\n",
              "      <td>pierrelouis</td>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>Male</td>\n",
              "      <td>1973-01-22</td>\n",
              "      <td>43</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Other</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7</td>\n",
              "      <td>marsha miles</td>\n",
              "      <td>marsha</td>\n",
              "      <td>miles</td>\n",
              "      <td>2013-11-30</td>\n",
              "      <td>Male</td>\n",
              "      <td>1971-08-22</td>\n",
              "      <td>44</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Other</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-11-30</td>\n",
              "      <td>2013-11-30</td>\n",
              "      <td>2013-12-01</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>853</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows Ã— 53 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                name   first         last compas_screening_date   sex  \\\n",
              "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
              "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
              "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
              "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
              "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
              "5   7        marsha miles  marsha        miles            2013-11-30  Male   \n",
              "\n",
              "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
              "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
              "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
              "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
              "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
              "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
              "5  1971-08-22   44          25 - 45             Other  ...               1   \n",
              "\n",
              "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
              "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
              "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
              "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
              "3        Medium        2013-01-13         NaN          NaN               1   \n",
              "4           Low        2013-03-26         NaN          NaN               2   \n",
              "5           Low        2013-11-30  2013-11-30   2013-12-01               0   \n",
              "\n",
              "  start   end event two_year_recid  \n",
              "0     0   327     0              0  \n",
              "1     9   159     1              1  \n",
              "2     0    63     0              1  \n",
              "3     0  1174     0              0  \n",
              "4     0  1102     0              0  \n",
              "5     1   853     0              0  \n",
              "\n",
              "[6 rows x 53 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# inspection of the first 6 rows of the dataset\n",
        "df_compas.head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XbRNw9iiF0v",
        "outputId": "48863105-5c41-47f9-a1b2-88457a008cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
            "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
            "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
            "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
            "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
            "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
            "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
            "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
            "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
            "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
            "       'decile_score.1', 'score_text', 'screening_date',\n",
            "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
            "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
            "       'start', 'end', 'event', 'two_year_recid'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# available labels for each row\n",
        "print(df_compas.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GUwwFM7BiF0w"
      },
      "outputs": [],
      "source": [
        "# removing unused columns\n",
        "df_LR7 = df_compas.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
        "       'age_cat', 'race', 'decile_score', 'juv_other_count',\n",
        "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
        "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
        "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
        "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
        "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
        "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
        "       'decile_score.1', 'score_text', 'screening_date',\n",
        "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
        "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
        "       'start', 'end', 'event'])\n",
        "\n",
        "# transforming string values into numerical\n",
        "df_LR7['sex'] = df_LR7['sex'].astype('category')\n",
        "df_LR7['sex'] = df_LR7['sex'].cat.codes\n",
        "\n",
        "df_LR7['c_charge_degree'] = df_LR7['c_charge_degree'].astype('category')\n",
        "df_LR7['c_charge_degree'] = df_LR7['c_charge_degree'].cat.codes\n",
        "\n",
        "df_LR7['c_charge_desc'] = df_LR7['c_charge_desc'].astype('category')\n",
        "df_LR7['c_charge_desc'] = df_LR7['c_charge_desc'].cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "QiJKiCoTiF0y",
        "outputId": "6fbeae18-5222-457b-f109-c30a39c73dfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sex                0\n",
              "age                0\n",
              "juv_fel_count      0\n",
              "juv_misd_count     0\n",
              "priors_count       0\n",
              "c_charge_degree    0\n",
              "c_charge_desc      0\n",
              "two_year_recid     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking for null values in the data => it has no null values\n",
        "df_LR7.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HTvlbFRAiF0z"
      },
      "outputs": [],
      "source": [
        "# splitting the dataset in features and the variable to predict\n",
        "\n",
        "X_overall_LR7 = df_LR7.drop(columns='two_year_recid')\n",
        "y_overall_LR7 = df_LR7['two_year_recid']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7WZ4XUniF00"
      },
      "source": [
        "#### Overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg2yl1oqiF01",
        "outputId": "f85a7c92-e29f-4307-9f6f-0a691fb45183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy overall: 67.58\n",
            "Mean of the F1-score: 59.94\n",
            "Standard deviation of the F1-score: 1.85\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=28)\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_overall_LR7 = cross_val_score(lr, X_overall_LR7, y_overall_LR7, cv=kf, scoring='accuracy')\n",
        "accuracy_overall_LR7 = round(np.average(kfscore_accuracy_overall_LR7) * 100, 2)\n",
        "print('Accuracy overall:', accuracy_overall_LR7)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_overall_LR7_std = round(np.std(kfscore_accuracy_overall_LR7) * 100, 2)\n",
        "table_overall_LR7 = str(accuracy_overall_LR7) + ' [+/-' + str(accuracy_overall_LR7_std) + ']'\n",
        "\n",
        "# F1-score\n",
        "kfscore_f1_overall_LR7 = cross_val_score(lr, X_overall_LR7, y_overall_LR7, cv=kf, scoring='f1')\n",
        "F1_mean_LR7 = round(np.mean(kfscore_f1_overall_LR7) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_LR7)\n",
        "\n",
        "# standard deviaton of the F1-score\n",
        "F1_std_LR7 = round(np.std(kfscore_f1_overall_LR7) * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_LR7)\n",
        "table_F1_LR7 = str(F1_mean_LR7) + ' [+/-' + str(F1_std_LR7) + ']'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0njPxTniF02"
      },
      "source": [
        "#### Black people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUTdybKliF03",
        "outputId": "71060da5-6055-4185-b02b-977f95eda6ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Black people: 66.88\n",
            "False Positive for Black people: 37.77\n",
            "False Negative for Black people: 28.72\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# dataset for Black people\n",
        "df_black_LR7 = df_compas.loc[df_compas['race'] == \"African-American\"]\n",
        "df_black_LR7 = df_black_LR7.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
        "       'age_cat', 'race', 'decile_score', 'juv_other_count',\n",
        "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
        "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
        "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
        "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
        "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
        "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
        "       'decile_score.1', 'score_text', 'screening_date',\n",
        "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
        "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
        "       'start', 'end', 'event'])\n",
        "\n",
        "# encoding\n",
        "df_black_LR7['sex'] = df_black_LR7['sex'].astype('category')\n",
        "df_black_LR7['sex'] = df_black_LR7['sex'].cat.codes\n",
        "df_black_LR7['c_charge_degree'] = df_black_LR7['c_charge_degree'].astype('category')\n",
        "df_black_LR7['c_charge_degree'] = df_black_LR7['c_charge_degree'].cat.codes\n",
        "df_black_LR7['c_charge_desc'] = df_black_LR7['c_charge_desc'].astype('category')\n",
        "df_black_LR7['c_charge_desc'] = df_black_LR7['c_charge_desc'].cat.codes\n",
        "\n",
        "# splitting the data\n",
        "X_black_LR7 = df_black_LR7.drop(columns='two_year_recid')\n",
        "y_black_LR7 = df_black_LR7['two_year_recid']\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_black_LR7 = cross_val_score(lr, X_black_LR7, y_black_LR7, cv=kf, scoring='accuracy')\n",
        "accuracy_black_LR7 = round(np.average(kfscore_accuracy_black_LR7) * 100, 2)\n",
        "print('Accuracy for Black people:', accuracy_black_LR7)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_black_LR7_std = round(np.std(kfscore_accuracy_black_LR7) * 100, 2)\n",
        "table_black_LR7 = str(accuracy_black_LR7) + ' [+/-' + str(accuracy_black_LR7_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_black_LR7 = cross_val_predict(lr, X_black_LR7, y_black_LR7, cv=kf)\n",
        "conf_mat_black_LR7 = confusion_matrix(y_black_LR7, y_pred_black_LR7, normalize='true')\n",
        "FP_black_LR7 = round(conf_mat_black_LR7[0,1] * 100, 2)\n",
        "FN_black_LR7 = round(conf_mat_black_LR7[1,0] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_LR7)\n",
        "print('False Negative for Black people:', FN_black_LR7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5miElifLiF04"
      },
      "source": [
        "#### White people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T1iBLNLiF04",
        "outputId": "f1ec883e-ce22-443f-ec63-1a0bae33cbe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for White people: 67.4\n",
            "False Positive for White people: 11.29\n",
            "False Negative for White people: 65.42\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# dataset for White people \n",
        "df_white_LR7 = df_compas.loc[df_compas['race'] == 'Caucasian']\n",
        "df_white_LR7 = df_white_LR7.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
        "       'age_cat', 'race', 'decile_score', 'juv_other_count',\n",
        "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
        "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
        "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
        "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
        "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
        "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
        "       'decile_score.1', 'score_text', 'screening_date',\n",
        "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
        "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
        "       'start', 'end', 'event'])\n",
        "\n",
        "# encoding\n",
        "df_white_LR7['sex'] = df_white_LR7['sex'].astype('category')\n",
        "df_white_LR7['sex'] = df_white_LR7['sex'].cat.codes\n",
        "df_white_LR7['c_charge_degree'] = df_white_LR7['c_charge_degree'].astype('category')\n",
        "df_white_LR7['c_charge_degree'] = df_white_LR7['c_charge_degree'].cat.codes\n",
        "df_white_LR7['c_charge_desc'] = df_white_LR7['c_charge_desc'].astype('category')\n",
        "df_white_LR7['c_charge_desc'] = df_white_LR7['c_charge_desc'].cat.codes\n",
        "\n",
        "# splitting the data\n",
        "X_white_LR7 = df_white_LR7.drop(columns='two_year_recid')\n",
        "y_white_LR7 = df_white_LR7['two_year_recid']\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_white_LR7 = cross_val_score(lr, X_white_LR7, y_white_LR7, cv=kf, scoring='accuracy')\n",
        "accuracy_white_LR7 = round(np.average(kfscore_accuracy_white_LR7) * 100, 2)\n",
        "print('Accuracy for White people:', accuracy_white_LR7)\n",
        "accuracy_white_LR7_std = round(np.std(kfscore_accuracy_overall_LR7) * 100, 2)\n",
        "table_white_LR7 = str(accuracy_overall_LR7) + ' [+/-' + str(accuracy_overall_LR7_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_white_LR7 = cross_val_predict(lr, X_white_LR7, y_white_LR7, cv=kf)\n",
        "conf_mat_white_LR7 = confusion_matrix(y_white_LR7, y_pred_white_LR7, normalize='true')\n",
        "FP_white_LR7 = round(conf_mat_white_LR7[0,1] * 100, 2)\n",
        "FN_white_LR7 = round(conf_mat_white_LR7[1,0] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_LR7)\n",
        "print('False Negative for White people:', FN_white_LR7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Percentages within the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of Black people: 51.23%\n",
            "Percentage of White people: 34.02%\n",
            "Percentage of female people: 19.34%\n",
            "Percentage of male people: 80.66%\n"
          ]
        }
      ],
      "source": [
        "# Black people\n",
        "percentage_black = round(len(df_black_LR7) / len(df_compas) * 100, 2)\n",
        "print(\"Percentage of Black people: \" + str(percentage_black) + \"%\")\n",
        "\n",
        "# White people\n",
        "percentage_white = round(len(df_white_LR7) / len(df_compas) * 100, 2)\n",
        "print(\"Percentage of White people: \" + str(percentage_white) + \"%\")\n",
        "\n",
        "# female\n",
        "df_female = df_compas.loc[df_compas['sex'] == \"Female\"]\n",
        "percentage_female = round(len(df_female) / len(df_compas) * 100, 2)\n",
        "print(\"Percentage of female people: \" + str(percentage_female) + \"%\")\n",
        "\n",
        "# male\n",
        "df_male = df_compas.loc[df_compas['sex'] == \"Male\"]\n",
        "percentage_male = round(len(df_male) / len(df_compas) * 100, 2)\n",
        "print(\"Percentage of male people: \" + str(percentage_male) + \"%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-DAylCuiF04"
      },
      "source": [
        "## Logistic Regression with 2 Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9la56gBiF05"
      },
      "source": [
        "#### Overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1fW6-triF05",
        "outputId": "ccec2a01-74c4-4fa2-dee5-c68f59b55cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy overall: 67.51\n",
            "Mean of the F1-score: 58.38\n",
            "Standard deviation of the F1-score: 3.06\n"
          ]
        }
      ],
      "source": [
        "# removing unused columns to only two features\n",
        "df_LR2 = df_LR7.drop(columns=['sex', 'c_charge_degree', 'c_charge_desc'])\n",
        "\n",
        "# add the total number of previous convictions as a feature \n",
        "df_LR2['total_number'] = df_LR2['juv_fel_count'] + df_LR2['juv_misd_count'] + df_LR2['priors_count']\n",
        "df_LR2 = df_LR2.drop(columns=['juv_fel_count', 'juv_misd_count', 'priors_count'])\n",
        "\n",
        "# splitting the data\n",
        "X_overall_LR2 = df_LR2.drop(columns='two_year_recid')\n",
        "y_overall_LR2 = df_LR2['two_year_recid']\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_overall_LR2 = cross_val_score(lr, X_overall_LR2, y_overall_LR2, cv=kf, scoring='accuracy')\n",
        "accuracy_overall_LR2 = round(np.average(kfscore_accuracy_overall_LR2) * 100, 2)\n",
        "print('Accuracy overall:', accuracy_overall_LR2)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_overall_LR2_std = round(np.std(kfscore_accuracy_overall_LR2) * 100, 2)\n",
        "table_overall_LR2 = str(accuracy_overall_LR2) + ' [+/-' + str(accuracy_overall_LR2_std) + ']'\n",
        "\n",
        "# F1-score\n",
        "kfscore_f1_overall_LR2 = cross_val_score(lr, X_overall_LR2, y_overall_LR2, cv=kf, scoring='f1')\n",
        "F1_mean_LR2 = round(np.mean(kfscore_f1_overall_LR2) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_LR2)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_LR2 = round(np.std(kfscore_f1_overall_LR2) * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_LR2)\n",
        "table_F1_LR2 = str(F1_mean_LR2) + ' [+/-' + str(F1_std_LR2) + ']'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4IiGLpdiF05"
      },
      "source": [
        "#### African-American people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XSb3okRiF06",
        "outputId": "be7c5283-b22b-4988-9633-9fa7363b6862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Black people: 67.56\n",
            "False Positive for Black people: 35.71\n",
            "False Negative for Black people: 28.93\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# dataset for Black people\n",
        "df_black_LR2 = df_black_LR7.drop(columns=['sex', 'c_charge_degree', 'c_charge_desc'])\n",
        "\n",
        "# add the total number of previous convictions as a feature \n",
        "df_black_LR2['total_number'] = df_black_LR2['juv_fel_count'] + df_black_LR2['juv_misd_count'] + df_black_LR2['priors_count']\n",
        "df_black_LR2 = df_black_LR2.drop(columns=['juv_fel_count', 'juv_misd_count', 'priors_count'])\n",
        "\n",
        "# splitting the data\n",
        "X_black_LR2 = df_black_LR2.drop(columns='two_year_recid')\n",
        "y_black_LR2 = df_black_LR2['two_year_recid']\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_black_LR2 = cross_val_score(lr, X_black_LR2, y_black_LR2, cv=kf, scoring='accuracy')\n",
        "accuracy_black_LR2 = round(np.average(kfscore_accuracy_black_LR2) * 100, 2)\n",
        "print('Accuracy for Black people:', accuracy_black_LR2)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_black_LR2_std = round(np.std(kfscore_accuracy_black_LR2) * 100, 2)\n",
        "table_black_LR2 = str(accuracy_black_LR2) + ' [+/-' + str(accuracy_black_LR2_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_black_LR2 = cross_val_predict(lr, X_black_LR2, y_black_LR2, cv=10)\n",
        "conf_mat_black_LR2 = confusion_matrix(y_black_LR2, y_pred_black_LR2, normalize='true')\n",
        "FP_black_LR2 = round(conf_mat_black_LR2[0,1] * 100, 2)\n",
        "FN_black_LR2 = round(conf_mat_black_LR2[1,0] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_LR2)\n",
        "print('False Negative for Black people:', FN_black_LR2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sWj0z89iF06"
      },
      "source": [
        "#### Caucasian people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbKe-GxbiF06",
        "outputId": "d25ddcd7-5478-425f-dbe9-adce943d0fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for White people: 67.97\n",
            "False Positive for White people: 10.48\n",
            "False Negative for White people: 65.32\n"
          ]
        }
      ],
      "source": [
        "# dataset for White people\n",
        "df_white_LR2 = df_white_LR7.drop(columns=['sex', 'c_charge_degree', 'c_charge_desc'])\n",
        "\n",
        "# add the total number of previous convictions as a feature \n",
        "df_white_LR2['total_number'] = df_white_LR2['juv_fel_count'] + df_white_LR2['juv_misd_count'] + df_white_LR2['priors_count']\n",
        "df_white_LR2 = df_white_LR2.drop(columns=['juv_fel_count', 'juv_misd_count', 'priors_count'])\n",
        "\n",
        "# splitting the data\n",
        "X_white_LR2 = df_white_LR2.drop(columns='two_year_recid')\n",
        "y_white_LR2 = df_white_LR2['two_year_recid']\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_white_LR2 = cross_val_score(lr, X_white_LR2, y_white_LR2, cv=kf, scoring='accuracy')\n",
        "accuracy_white_LR2 = round(np.average(kfscore_accuracy_white_LR2) * 100, 2)\n",
        "print('Accuracy for White people:', accuracy_white_LR2)\n",
        "\n",
        "#standard deviation\n",
        "accuracy_white_LR2_std = round(np.std(kfscore_accuracy_overall_LR2) * 100, 2)\n",
        "table_white_LR2 = str(accuracy_white_LR2) + ' [+/-' + str(accuracy_white_LR2_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_white_LR2 = cross_val_predict(lr, X_white_LR2, y_white_LR2, cv=10)\n",
        "conf_mat_white_LR2 = confusion_matrix(y_white_LR2, y_pred_white_LR2, normalize='true')\n",
        "FP_white_LR2 = round(conf_mat_white_LR2[0,1] * 100, 2)\n",
        "FN_white_LR2 = round(conf_mat_white_LR2[1,0] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_LR2)\n",
        "print('False Negative for White people:', FN_white_LR2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JKHiPsZiF06"
      },
      "source": [
        "## Nonlinear Support Vector Machine with radial basis kernel and 7 Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izrRoe9IiF07",
        "outputId": "230f2924-45c1-4b53-a782-860c95c5cea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy overall: 62.84\n",
            "Mean of the F1-score: 50.11\n",
            "Standard deviation of the F1-score: 1.98\n",
            "Accuracy for Black people: 61.2\n",
            "Accuracy for White people: 61.74\n",
            "False Positive for Black people: 37.77\n",
            "False Negative for Black people: 28.72\n",
            "False Positive for White people: 11.29\n",
            "False Negative for White people: 65.42\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='rbf')\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_overall_SVM = cross_val_score(svm, X_overall_LR7, y_overall_LR7, cv=kf, scoring='accuracy')\n",
        "accuracy_overall_SVM = round(np.average(kfscore_accuracy_overall_SVM) * 100, 2)\n",
        "print('Accuracy overall:', accuracy_overall_SVM)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_overall_SVM_std = round(np.std(kfscore_accuracy_overall_SVM) * 100, 2)\n",
        "table_overall_SVM = str(accuracy_overall_SVM) + ' [+/-' + str(accuracy_overall_SVM_std) + ']'\n",
        "\n",
        "# F1-score\n",
        "kfscore_f1_overall_SVM = cross_val_score(svm, X_overall_LR7, y_overall_LR7, cv=kf, scoring='f1')\n",
        "F1_mean_SVM = round(np.mean(kfscore_f1_overall_SVM) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_SVM)\n",
        "\n",
        "# standard deviaton of the F1-score\n",
        "F1_std_SVM = round(np.std(kfscore_f1_overall_SVM * 100), 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_SVM)\n",
        "table_F1_SVM = str(F1_mean_SVM) + ' [+/-' + str(F1_std_SVM) + ']'\n",
        "\n",
        "# accuracy for Black dataset\n",
        "kfscore_accuracy_black_SVM = cross_val_score(svm, X_black_LR7, y_black_LR7, cv=kf, scoring='accuracy')\n",
        "accuracy_black_SVM = round(np.average(kfscore_accuracy_black_SVM) * 100, 2)\n",
        "print('Accuracy for Black people:', accuracy_black_SVM)\n",
        "\n",
        "# standard deviation for Black dataset\n",
        "accuracy_black_SVM_std = round(np.std(kfscore_accuracy_black_SVM) * 100, 2)\n",
        "table_black_SVM = str(accuracy_black_SVM) + ' [+/-' + str(accuracy_black_SVM_std) + ']'\n",
        "\n",
        "# accuracy for White dataset\n",
        "kfscore_accuracy_white_SVM = cross_val_score(svm, X_white_LR7, y_white_LR7, cv=kf, scoring='accuracy')\n",
        "accuracy_white_SVM = round(np.average(kfscore_accuracy_white_SVM) * 100, 2)\n",
        "print('Accuracy for White people:', accuracy_white_SVM)\n",
        "\n",
        "# standard deviation for White dataset\n",
        "accuracy_white_SVM_std = round(np.std(kfscore_accuracy_white_SVM) * 100, 2)\n",
        "table_white_SVM = str(accuracy_white_SVM) + ' [+/-' + str(accuracy_white_SVM_std) + ']'\n",
        "\n",
        "# false positive and false negative for Black dataset\n",
        "y_pred_black_SVM = cross_val_predict(svm, X_black_LR7, y_black_LR7, cv=kf)\n",
        "conf_mat_black_SVM = confusion_matrix(y_black_LR7, y_pred_black_LR7, normalize='true')\n",
        "FP_black_SVM = round(conf_mat_black_SVM[0,1] * 100, 2)\n",
        "FN_black_SVM = round(conf_mat_black_SVM[1,0] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_SVM)\n",
        "print('False Negative for Black people:', FN_black_SVM)\n",
        "\n",
        "# false positive and false negative for White dataset\n",
        "y_pred_white_SVM = cross_val_predict(svm, X_white_LR7, y_white_LR7, cv=kf)\n",
        "conf_mat_white_SVM = confusion_matrix(y_white_LR7, y_pred_white_LR7, normalize='true')\n",
        "FP_white_SVM = round(conf_mat_white_SVM[0,1] * 100, 2)\n",
        "FN_white_SVM = round(conf_mat_white_SVM[1,0] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_SVM)\n",
        "print('False Negative for White people:', FN_white_SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfMyYlRWiF07"
      },
      "source": [
        "## Logistic Regression with 8 features (including race)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbdF81IeiF07"
      },
      "source": [
        "#### Overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xszu2qvniF07",
        "outputId": "ccfe5446-c216-470f-d56d-e7d7e27c73f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy overall: 67.74\n",
            "Mean of the F1-score: 60.42\n",
            "Standard deviation of the F1-score: 2.07\n"
          ]
        }
      ],
      "source": [
        "# removing unused columns\n",
        "df_LR8 = df_compas.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
        "       'age_cat', 'decile_score', 'juv_other_count',\n",
        "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
        "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
        "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
        "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
        "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
        "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
        "       'decile_score.1', 'score_text', 'screening_date',\n",
        "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
        "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
        "       'start', 'end', 'event'])\n",
        "\n",
        "# encoding\n",
        "df_LR8['sex'] = df_LR8['sex'].astype('category')\n",
        "df_LR8['sex'] = df_LR8['sex'].cat.codes\n",
        "df_LR8['c_charge_degree'] = df_LR8['c_charge_degree'].astype('category')\n",
        "df_LR8['c_charge_degree'] = df_LR8['c_charge_degree'].cat.codes\n",
        "df_LR8['c_charge_desc'] = df_LR8['c_charge_desc'].astype('category')\n",
        "df_LR8['c_charge_desc'] = df_LR8['c_charge_desc'].cat.codes\n",
        "df_LR8['race'] = df_LR8['race'].astype('category')\n",
        "df_LR8['race'] = df_LR8['race'].cat.codes\n",
        "\n",
        "# splitting the data\n",
        "X_overall_LR8 = df_LR8.drop(columns='two_year_recid')\n",
        "y_overall_LR8 = df_LR8['two_year_recid']\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_overall_LR8 = cross_val_score(lr, X_overall_LR8, y_overall_LR8, cv=kf, scoring='accuracy')\n",
        "accuracy_overall_LR8 = round(np.average(kfscore_accuracy_overall_LR8) * 100, 2)\n",
        "print('Accuracy overall:', accuracy_overall_LR8)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_overall_LR8_std = round(np.std(kfscore_accuracy_overall_LR8) * 100, 2)\n",
        "table_overall_LR8 = str(accuracy_overall_LR8) + ' [+/-' + str(accuracy_overall_LR8_std) + ']'\n",
        "\n",
        "# F1-score\n",
        "kfscore_f1_overall_LR8 = cross_val_score(lr, X_overall_LR8, y_overall_LR8, cv=kf, scoring='f1')\n",
        "F1_mean_LR8 = round(np.mean(kfscore_f1_overall_LR8) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_LR8)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_LR8 = round(np.std(kfscore_f1_overall_LR8) * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_LR8)\n",
        "table_F1_LR8 = str(F1_mean_LR8) + ' [+/-' + str(F1_std_LR8) + ']'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JE0zi2JiF08"
      },
      "source": [
        "#### African-American people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PkQtk5IiF08",
        "outputId": "5e521ba5-db99-494b-ec44-d2b202afb672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Black people: 66.91\n",
            "False Positive for Black people: 37.77\n",
            "False Negative for Black people: 28.67\n"
          ]
        }
      ],
      "source": [
        "# dataset for Black people\n",
        "df_black_LR8 = df_compas.loc[df_compas['race'] == \"African-American\"]\n",
        "df_black_LR8 = df_black_LR8.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
        "       'age_cat', 'decile_score', 'juv_other_count',\n",
        "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
        "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
        "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
        "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
        "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
        "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
        "       'decile_score.1', 'score_text', 'screening_date',\n",
        "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
        "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
        "       'start', 'end', 'event'])\n",
        "\n",
        "# encoding\n",
        "df_black_LR8['sex'] = df_black_LR8['sex'].astype('category')\n",
        "df_black_LR8['sex'] = df_black_LR8['sex'].cat.codes\n",
        "df_black_LR8['c_charge_degree'] = df_black_LR8['c_charge_degree'].astype('category')\n",
        "df_black_LR8['c_charge_degree'] = df_black_LR8['c_charge_degree'].cat.codes\n",
        "df_black_LR8['c_charge_desc'] = df_black_LR8['c_charge_desc'].astype('category')\n",
        "df_black_LR8['c_charge_desc'] = df_black_LR8['c_charge_desc'].cat.codes\n",
        "df_black_LR8['race'] = df_black_LR8['race'].astype('category')\n",
        "df_black_LR8['race'] = df_black_LR8['race'].cat.codes\n",
        "\n",
        "# splitting the data\n",
        "X_black_LR8 = df_black_LR8.drop(columns='two_year_recid')\n",
        "y_black_LR8 = df_black_LR8['two_year_recid']\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_black_LR8 = cross_val_score(lr, X_black_LR8, y_black_LR8, cv=kf, scoring='accuracy')\n",
        "accuracy_black_LR8 = round(np.average(kfscore_accuracy_black_LR8) * 100, 2)\n",
        "print('Accuracy for Black people:', accuracy_black_LR8)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_black_LR8_std = round(np.std(kfscore_accuracy_black_LR8) * 100, 2)\n",
        "table_black_LR8 = str(accuracy_black_LR8) + ' [+/-' + str(accuracy_black_LR8_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_black_LR8 = cross_val_predict(lr, X_black_LR8, y_black_LR8, cv=kf)\n",
        "conf_mat_black_LR8 = confusion_matrix(y_black_LR8, y_pred_black_LR8, normalize='true')\n",
        "FP_black_LR8 = round(conf_mat_black_LR8[0,1] * 100, 2)\n",
        "FN_black_LR8 = round(conf_mat_black_LR8[1,0] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_LR8)\n",
        "print('False Negative for Black people:', FN_black_LR8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izempWdUiF08"
      },
      "source": [
        "#### Caucasian people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baoH4EmTiF08",
        "outputId": "052f66da-25ed-4000-bf0e-1f31ff201181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for White people: 67.4\n",
            "False Positive for White people: 11.29\n",
            "False Negative for White people: 65.42\n"
          ]
        }
      ],
      "source": [
        "# dataset for White people\n",
        "df_white_LR8 = df_compas.loc[df_compas['race'] == 'Caucasian']\n",
        "df_white_LR8 = df_white_LR8.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
        "       'age_cat', 'decile_score', 'juv_other_count',\n",
        "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
        "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
        "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
        "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
        "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
        "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
        "       'decile_score.1', 'score_text', 'screening_date',\n",
        "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
        "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
        "       'start', 'end', 'event'])\n",
        "\n",
        "# encoding\n",
        "df_white_LR8['sex'] = df_white_LR8['sex'].astype('category')\n",
        "df_white_LR8['sex'] = df_white_LR8['sex'].cat.codes\n",
        "df_white_LR8['c_charge_degree'] = df_white_LR8['c_charge_degree'].astype('category')\n",
        "df_white_LR8['c_charge_degree'] = df_white_LR8['c_charge_degree'].cat.codes\n",
        "df_white_LR8['c_charge_desc'] = df_white_LR8['c_charge_desc'].astype('category')\n",
        "df_white_LR8['c_charge_desc'] = df_white_LR8['c_charge_desc'].cat.codes\n",
        "df_white_LR8['race'] = df_white_LR8['race'].astype('category')\n",
        "df_white_LR8['race'] = df_white_LR8['race'].cat.codes\n",
        "\n",
        "# splitting the data\n",
        "X_white_LR8 = df_white_LR8.drop(columns='two_year_recid')\n",
        "y_white_LR8 = df_white_LR8['two_year_recid']\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_white_LR8 = cross_val_score(lr, X_white_LR8, y_white_LR8, cv=kf, scoring='accuracy')\n",
        "accuracy_white_LR8 = round(np.average(kfscore_accuracy_white_LR8) * 100, 2)\n",
        "print('Accuracy for White people:', accuracy_white_LR8)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_white_LR8_std = round(np.std(kfscore_accuracy_overall_LR8) * 100, 2)\n",
        "table_white_LR8 = str(accuracy_overall_LR8) + ' [+/-' + str(accuracy_overall_LR8_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_white_LR8 = cross_val_predict(lr, X_white_LR8, y_white_LR8, cv=kf)\n",
        "conf_mat_white_LR8 = confusion_matrix(y_white_LR8, y_pred_white_LR8, normalize='true')\n",
        "FP_white_LR8 = round(conf_mat_white_LR8[0,1] * 100, 2)\n",
        "FN_white_LR8 = round(conf_mat_white_LR8[1,0] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_LR8)\n",
        "print('False Negative for White people:', FN_white_LR8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Further Observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q27l7iXEiF09"
      },
      "source": [
        "## Logistic Regression with all features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcr4pTLhiF09"
      },
      "source": [
        "#### Overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0Rnc8tdtiF09"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# splitting the data\n",
        "X_overall_LR = df_compas.drop(columns='two_year_recid')\n",
        "y_overall_LR = df_compas['two_year_recid']\n",
        "\n",
        "# sort data into numerical and categorical columns\n",
        "numerical_cols = X_overall_LR.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = X_overall_LR.select_dtypes(include=['object']).columns\n",
        "\n",
        "# pipeline to encode the data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0.0)),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='-1')),\n",
        "    ('enocder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# preprocessor to combine the transformers\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ").set_output(transform='pandas')\n",
        "\n",
        "# add the preprocessor to the model\n",
        "lr_process = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', lr)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Buq_Z0jWiF09",
        "outputId": "1624c53e-4fb1-4a89-bc1a-c0697fab372a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy overall: 97.6\n",
            "Mean of the F1-score: 97.41\n",
            "Standard deviation of the F1-score: 0.68\n"
          ]
        }
      ],
      "source": [
        "# accuracy\n",
        "kfscore_accuracy_overall_LR = cross_val_score(lr_process, X_overall_LR, y_overall_LR, cv=kf, scoring='accuracy')\n",
        "accuracy_overall_LR = round(np.average(kfscore_accuracy_overall_LR) * 100, 2)\n",
        "print('Accuracy overall:', accuracy_overall_LR)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_overall_LR_std = round(np.std(kfscore_accuracy_overall_LR) * 100, 2)\n",
        "table_overall_LR = str(accuracy_overall_LR) + ' [+/-' + str(accuracy_overall_LR_std) + ']'\n",
        "\n",
        "# F1-score\n",
        "kfscore_f1_overall_LR = cross_val_score(lr_process, X_overall_LR, y_overall_LR, cv=kf, scoring='f1')\n",
        "F1_mean_LR = round(np.mean(kfscore_f1_overall_LR) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_LR)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_LR = round(np.std(kfscore_f1_overall_LR) * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_LR)\n",
        "table_F1_LR = str(F1_mean_LR) + ' [+/-' + str(F1_std_LR) + ']'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mw4gVpriF0-"
      },
      "source": [
        "#### African-American people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "w42aHbcbiF0-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Black people: 96.78\n",
            "False Positive for Black people: 6.35\n",
            "False Negative for Black people: 0.26\n"
          ]
        }
      ],
      "source": [
        "# dataset for Black people\n",
        "df_black_LR = df_compas.loc[df_compas['race'] == \"African-American\"]\n",
        "\n",
        "# splitting the data\n",
        "X_black_LR = df_black_LR.drop(columns='two_year_recid')\n",
        "y_black_LR = df_black_LR['two_year_recid']\n",
        "\n",
        "# sort data into numerical and categorical columns\n",
        "numerical_cols = X_black_LR.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = X_black_LR.select_dtypes(include=['object']).columns\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_black_LR = cross_val_score(lr_process, X_black_LR, y_black_LR, cv=kf, scoring='accuracy')\n",
        "accuracy_black_LR = round(np.average(kfscore_accuracy_black_LR) * 100, 2)\n",
        "print('Accuracy for Black people:', accuracy_black_LR)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_black_LR_std = round(np.std(kfscore_accuracy_black_LR) * 100, 2)\n",
        "table_black_LR = str(accuracy_black_LR) + ' [+/-' + str(accuracy_black_LR_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_black_LR = cross_val_predict(lr_process, X_black_LR, y_black_LR, cv=kf)\n",
        "conf_mat_black_LR = confusion_matrix(y_black_LR, y_pred_black_LR, normalize='true')\n",
        "FP_black_LR = round(conf_mat_black_LR[0,1] * 100, 2)\n",
        "FN_black_LR = round(conf_mat_black_LR[1,0] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_LR)\n",
        "print('False Negative for Black people:',  FN_black_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ehPxPMGiF0-"
      },
      "source": [
        "#### Caucasian people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2SUwnQcfiF0-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for White people: 97.68\n",
            "False Positive for White people: 3.83\n",
            "False Negative for White people: 0.0\n"
          ]
        }
      ],
      "source": [
        "# dataset for White people\n",
        "df_white_LR = df_compas.loc[df_compas['race'] == 'Caucasian']\n",
        "\n",
        "# splitting the data\n",
        "X_white_LR = df_white_LR.drop(columns='two_year_recid')\n",
        "y_white_LR = df_white_LR['two_year_recid']\n",
        "\n",
        "# sort data into numerical and categorical columns\n",
        "numerical_cols = X_white_LR.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = X_white_LR.select_dtypes(include=['object']).columns\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_white_LR = cross_val_score(lr_process, X_white_LR, y_white_LR, cv=kf, scoring='accuracy')\n",
        "accuracy_white_LR = round(np.average(kfscore_accuracy_white_LR) * 100, 2)\n",
        "print('Accuracy for White people:', accuracy_white_LR)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_white_LR_std = round(np.std(kfscore_accuracy_overall_LR) * 100, 2)\n",
        "table_white_LR = str(accuracy_overall_LR) + ' [+/-' + str(accuracy_overall_LR_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_white_LR = cross_val_predict(lr_process, X_white_LR, y_white_LR, cv=kf)\n",
        "conf_mat_white_LR = confusion_matrix(y_white_LR, y_pred_white_LR, normalize='true')\n",
        "FP_white_LR = round(conf_mat_white_LR[0,1] * 100, 2)\n",
        "FN_white_LR = round(conf_mat_white_LR[1,0] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_LR)\n",
        "print('False Negative for White people:', FN_white_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wtawusdiF0_"
      },
      "source": [
        "####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNb7ExPIiF1A"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pDcayG3iF1B"
      },
      "source": [
        "## Mitigation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBAxb_QbiF1B"
      },
      "source": [
        "#### Vanilla XG Boost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEiiVoeFiF1B",
        "outputId": "e5b46a5a-2d08-40e5-c191-75f39f6c28cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of the F1-score: 60.05\n",
            "Standard deviation of the F1-score: 1.84\n",
            "False Positive for Black people: 34.15\n",
            "False Negative for Black people: 34.67\n",
            "False Positive for White people: 24.73\n",
            "False Negative for White people: 54.24\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "# the chosen parameters originate from the paper about Tree Boosting Methods\n",
        "\n",
        "# parameters \n",
        "params_vanilla = {\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.3,\n",
        "    'subsample': 1,\n",
        "    'colsample_bytree': 1,\n",
        "}\n",
        "\n",
        "# model\n",
        "xgb_vanilla = XGBClassifier(**params_vanilla)\n",
        "\n",
        "# F1-score\n",
        "xgb_cv = cross_val_score(xgb_vanilla, X_overall_LR8, y_overall_LR8, cv=kf, scoring='f1')\n",
        "F1_mean_vanilla = round(np.mean(xgb_cv) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_vanilla)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_vanilla = round(np.std(xgb_cv) * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_vanilla)\n",
        "\n",
        "# false positive and false negative for Black dataset\n",
        "y_pred_black_vanilla = cross_val_predict(xgb_vanilla, X_black_LR8, y_black_LR8, cv=kf)\n",
        "conf_mat_black_vanilla = confusion_matrix(y_black_LR8, y_pred_black_vanilla, normalize='true')\n",
        "FP_black_vanilla = round(conf_mat_black_vanilla[0,1] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_vanilla)\n",
        "FN_black_vanilla = round(conf_mat_black_vanilla[1,0] * 100, 2)\n",
        "print('False Negative for Black people:', FN_black_vanilla)\n",
        "\n",
        "# false positive and false negative for White dataset\n",
        "y_pred_white_vanilla = cross_val_predict(xgb_vanilla, X_white_LR8, y_white_LR8, cv=kf)\n",
        "conf_mat_white_vanilla = confusion_matrix(y_white_LR8, y_pred_white_vanilla, normalize='true')\n",
        "FP_white_vanilla = round(conf_mat_white_vanilla[0,1] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_vanilla)\n",
        "FN_white_vanilla = round(conf_mat_white_vanilla[1,0] * 100, 2)\n",
        "print('False Negative for White people:', FN_white_vanilla)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN6R3pHliF1C"
      },
      "source": [
        "#### XG Boost with RandomizedSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uBk-VUuiF1C",
        "outputId": "714bb725-b43e-46f4-d4f3-112812d792ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of the F1-score: 63.91\n",
            "Standard deviation of the F1-score: 2.66\n",
            "False Positive for Black people: 33.15\n",
            "False Negative for Black people: 31.51\n",
            "False Positive for White people: 15.52\n",
            "False Negative for White people: 57.56\n"
          ]
        }
      ],
      "source": [
        "# beginning parameters for tuning are from the paper about Tree Boosting Methods\n",
        "# param = {\n",
        "#     'max_depth': [3, 6, 12, 20],\n",
        "#     'learning_rate': [0.02, 0.1, 0.2],\n",
        "#     'subsample': [0.4, 0.8, 1],\n",
        "#     'colsample_bytree': [0.4, 0.6, 1],\n",
        "#     'n_estimators': [100, 1000, 5000],\n",
        "# }\n",
        "\n",
        "# parameters\n",
        "param_rs = {\n",
        "    'max_depth': [3],\n",
        "    'learning_rate': [0.1],\n",
        "    'subsample': [1],\n",
        "    'colsample_bytree': [0.6],\n",
        "    'n_estimators': [100],\n",
        "}\n",
        "\n",
        "# model\n",
        "xgb_rs = XGBClassifier()\n",
        "\n",
        "# randomized search and tuning\n",
        "random_search = RandomizedSearchCV(xgb_rs, param_distributions=param_rs, scoring='f1', cv=kf, n_iter=1)\n",
        "random_search.fit(X_overall_LR8, y_overall_LR8)\n",
        "\n",
        "# F1-score\n",
        "F1_mean_rs = round(np.mean(random_search.score(X_overall_LR8, y_overall_LR8)) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_rs)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_rs = random_search.cv_results_['std_test_score']\n",
        "F1_std_rs_rounded = round(F1_std_rs[0] * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_rs_rounded)\n",
        "\n",
        "# false positive and false negative for Black dataset\n",
        "y_pred_black_rs = cross_val_predict(random_search, X_black_LR8, y_black_LR8, cv=kf)\n",
        "conf_mat_black_rs = confusion_matrix(y_black_LR8, y_pred_black_rs, normalize='true')\n",
        "FP_black_rs = round(conf_mat_black_rs[0,1] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_rs)\n",
        "FN_black_rs = round(conf_mat_black_rs[1,0] * 100, 2)\n",
        "print('False Negative for Black people:', FN_black_rs)\n",
        "\n",
        "# false positive and false negative for White dataset\n",
        "y_pred_white_rs = cross_val_predict(random_search, X_white_LR8, y_white_LR8, cv=kf)\n",
        "conf_mat_white_rs = confusion_matrix(y_white_LR8, y_pred_white_rs, normalize='true')\n",
        "FP_white_rs = round(conf_mat_white_rs[0,1] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_rs)\n",
        "FN_white_rs = round(conf_mat_white_rs[1,0] * 100, 2)\n",
        "print('False Negative for White people:', FN_white_rs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI-6nBLRiF1D"
      },
      "source": [
        "#### XG Boost with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6JFTmA0iF1D",
        "outputId": "2b735a98-63ac-46eb-84c2-28a962d9eadd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of the F1-score: 64.64\n",
            "Standard deviation of the F1-score: 2.58\n",
            "False Positive for Black people: 33.15\n",
            "False Negative for Black people: 31.51\n",
            "False Positive for White people: 15.52\n",
            "False Negative for White people: 57.56\n"
          ]
        }
      ],
      "source": [
        "# beginning parameters for tuning are from the paper about Tree Boosting Methods\n",
        "# param = {\n",
        "#     'max_depth': [3, 6, 12, 20],\n",
        "#     'learning_rate': [0.02, 0.1, 0.2],\n",
        "#     'subsample': [0.4, 0.8, 1],\n",
        "#     'colsample_bytree': [0.4, 0.6, 1],\n",
        "#     'n_estimators': [100, 1000, 5000],\n",
        "# }\n",
        "\n",
        "# parameters\n",
        "param_gs = {\n",
        "    'max_depth': [3],\n",
        "    'learning_rate': [0.1],\n",
        "    'subsample': [0.4],\n",
        "    'colsample_bytree': [0.6],\n",
        "    'n_estimators': [100],\n",
        "}\n",
        "\n",
        "# model\n",
        "xgb_gs = XGBClassifier()\n",
        "\n",
        "# grid search and tuning\n",
        "grid_search = GridSearchCV(xgb_gs, param_grid=param_gs, scoring='f1', cv=kf, n_jobs=-1)\n",
        "grid_search.fit(X_overall_LR8, y_overall_LR8)\n",
        "\n",
        "# F1-score\n",
        "F1_mean_gs = round(np.mean(grid_search.score(X_overall_LR8, y_overall_LR8)) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_gs)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_gs = grid_search.cv_results_['std_test_score']\n",
        "F1_std_gs_rounded = round(F1_std_gs[0] * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_gs_rounded)\n",
        "\n",
        "# false positive and false negative for Black dataset\n",
        "y_pred_black_gs = cross_val_predict(grid_search, X_black_LR8, y_black_LR8, cv=kf)\n",
        "conf_mat_black_gs = confusion_matrix(y_black_LR8, y_pred_black_gs, normalize='true')\n",
        "FP_black_gs = round(conf_mat_black_gs[0,1] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_rs)\n",
        "FN_black_gs = round(conf_mat_black_gs[1,0] * 100, 2)\n",
        "print('False Negative for Black people:', FN_black_rs)\n",
        "\n",
        "# false positive and false negative for White dataset\n",
        "y_pred_white_gs = cross_val_predict(grid_search, X_white_LR8, y_white_LR8, cv=kf)\n",
        "conf_mat_white_gs = confusion_matrix(y_white_LR8, y_pred_white_gs, normalize='true')\n",
        "FP_white_gs = round(conf_mat_white_gs[0,1] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_rs)\n",
        "FN_white_gs = round(conf_mat_white_gs[1,0] * 100, 2)\n",
        "print('False Negative for White people:', FN_white_rs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKPcxjGriF1D"
      },
      "source": [
        "#### Grid Search with XG Boost and Fairlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0710--OiF1D",
        "outputId": "90a563cb-69d5-45fc-90f1-36f9a48bbcc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of the Accuracy: 69.98\n",
            "Mean of the F1-score: 64.95\n",
            "Standard deviation of the F1-score: 2.77\n",
            "False Positive for Black people: 34.09\n",
            "False Negative for Black people: 30.56\n",
            "False Positive for White people: 17.88\n",
            "False Negative for White people: 56.73\n"
          ]
        }
      ],
      "source": [
        "from fairlearn.preprocessing import CorrelationRemover\n",
        "\n",
        "# transforming the data with the correlation remover\n",
        "cr = CorrelationRemover(sensitive_feature_ids=['race'])\n",
        "X_overall_fairlearn = cr.fit_transform(X_overall_LR8)\n",
        "\n",
        "# beginning parameters for tuning are from the paper about Tree Boosting Methods\n",
        "# param = {\n",
        "#     'max_depth': [3, 6, 12, 20],\n",
        "#     'learning_rate': [0.02, 0.1, 0.2],\n",
        "#     'subsample': [0.4, 0.8, 1],\n",
        "#     'colsample_bytree': [0.4, 0.6, 1],\n",
        "#     'n_estimators': [100, 1000, 5000],\n",
        "# }\n",
        "\n",
        "# parameters\n",
        "param_gs_cr = {\n",
        "    'max_depth': [3],\n",
        "    'learning_rate': [0.2],\n",
        "    'subsample': [0.4],\n",
        "    'colsample_bytree': [0.4],\n",
        "    'n_estimators': [100],\n",
        "}\n",
        "\n",
        "# model\n",
        "xgb_gs_cr = XGBClassifier()\n",
        "\n",
        "# grid search and tuning\n",
        "grid_search_cr = GridSearchCV(xgb_gs_cr, param_grid=param_gs_cr, scoring='f1', cv=kf, n_jobs=-1)\n",
        "grid_search_cr.fit(X_overall_fairlearn, y_overall_LR8)\n",
        "\n",
        "# Accuracy\n",
        "grid_search_cr_acc = GridSearchCV(xgb_gs_cr, param_grid=param_gs_cr, scoring='accuracy', cv=kf, n_jobs=-1)\n",
        "grid_search_cr_acc.fit(X_overall_fairlearn, y_overall_LR8)\n",
        "acc_mean_gs_cr = round(np.mean(grid_search_cr_acc.score(X_overall_fairlearn, y_overall_LR8)) * 100, 2)\n",
        "print('Mean of the Accuracy:', acc_mean_gs_cr)\n",
        "\n",
        "# F1-score\n",
        "F1_mean_gs_cr = round(np.mean(grid_search_cr.score(X_overall_fairlearn, y_overall_LR8)) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_gs_cr)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_gs_cr = grid_search_cr.cv_results_['std_test_score']\n",
        "F1_std_gs_cr_rounded = round(F1_std_gs_cr[0] * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_gs_cr_rounded)\n",
        "\n",
        "# false positive and false negative for Black dataset \n",
        "X_black_fairlearn = cr.fit_transform(X_black_LR8)\n",
        "y_pred_black_gs_cr = cross_val_predict(grid_search_cr, X_black_fairlearn, y_black_LR8, cv=kf)\n",
        "conf_mat_black_gs_cr = confusion_matrix(y_black_LR8, y_pred_black_gs_cr, normalize='true')\n",
        "FP_black_gs_cr = round(conf_mat_black_gs_cr[0,1] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_gs_cr)\n",
        "FN_black_gs_cr = round(conf_mat_black_gs_cr[1,0] * 100, 2)\n",
        "print('False Negative for Black people:', FN_black_gs_cr)\n",
        "\n",
        "# false positive and false negative for White dataset\n",
        "X_white_fairlearn = cr.fit_transform(X_white_LR8)\n",
        "y_pred_white_gs_cr = cross_val_predict(grid_search_cr, X_white_fairlearn, y_white_LR8, cv=kf)\n",
        "conf_mat_white_gs_cr = confusion_matrix(y_white_LR8, y_pred_white_gs_cr, normalize='true')\n",
        "FP_white_gs_cr = round(conf_mat_white_gs_cr[0,1] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_gs_cr)\n",
        "FN_white_gs_cr = round(conf_mat_white_gs_cr[1,0] * 100, 2)\n",
        "print('False Negative for White people:', FN_white_gs_cr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### XGBoost with all Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
        "\n",
        "# XGBoost without any parameters\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# splitting the data\n",
        "X_overall_LR = df_compas.drop(columns='two_year_recid')\n",
        "y_overall_LR = df_compas['two_year_recid']\n",
        "\n",
        "# sort data into numerical and categorical columns\n",
        "numerical_cols = X_overall_LR.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = X_overall_LR.select_dtypes(include=['object']).columns\n",
        "\n",
        "# pipeline to encode the data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0.0)),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='-1')),\n",
        "    ('enocder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# One Hot Encoder uses special character like [, ] or < but they need to be removed \n",
        "def clean_feature_names(X):\n",
        "    X.columns = X.columns.str.replace(r'[\\[\\]<]', '', regex=True)\n",
        "    return X\n",
        "\n",
        "# use it as an additional transformer in the final pipeline\n",
        "cleaner_transformer = FunctionTransformer(clean_feature_names)\n",
        "\n",
        "# preprocessor to combine the transformers\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ").set_output(transform='pandas')\n",
        "\n",
        "# add the preprocessor to the model\n",
        "xgb_process = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('cleaner', cleaner_transformer),\n",
        "    ('model', xgb)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy overall: 98.96\n",
            "Mean of the F1-score: 98.85\n",
            "Standard deviation of the F1-score: 0.43\n"
          ]
        }
      ],
      "source": [
        "# accuracy\n",
        "kfscore_accuracy_overall_XGB = cross_val_score(xgb_process, X_overall_LR, y_overall_LR, cv=kf, scoring='accuracy')\n",
        "accuracy_overall_XGB = round(np.average(kfscore_accuracy_overall_XGB) * 100, 2)\n",
        "print('Accuracy overall:', accuracy_overall_XGB)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_overall_XGB_std = round(np.std(kfscore_accuracy_overall_XGB) * 100, 2)\n",
        "table_overall_XGB = str(accuracy_overall_XGB) + ' [+/-' + str(accuracy_overall_XGB_std) + ']'\n",
        "\n",
        "# F1-score\n",
        "kfscore_f1_overall_XGB = cross_val_score(xgb_process, X_overall_LR, y_overall_LR, cv=kf, scoring='f1')\n",
        "F1_mean_XGB = round(np.mean(kfscore_f1_overall_XGB) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_XGB)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_XGB = round(np.std(kfscore_f1_overall_XGB) * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_XGB)  \n",
        "table_F1_XGB = str(F1_mean_XGB) + ' [+/-' + str(F1_std_XGB) + ']'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard deviation for overall accuracy: 0.39\n"
          ]
        }
      ],
      "source": [
        "print('Standard deviation for overall accuracy:', accuracy_overall_XGB_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### African-American people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Black people: 98.4\n",
            "False Positive for Black people: 2.4\n",
            "False Negative for Black people: 0.84\n"
          ]
        }
      ],
      "source": [
        "# dataset for Black people\n",
        "df_black_LR = df_compas.loc[df_compas['race'] == \"African-American\"]\n",
        "\n",
        "# splitting the data\n",
        "X_black_LR = df_black_LR.drop(columns='two_year_recid')\n",
        "y_black_LR = df_black_LR['two_year_recid']\n",
        "\n",
        "# sort data into numerical and categorical columns\n",
        "numerical_cols = X_black_LR.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = X_black_LR.select_dtypes(include=['object']).columns\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_black_XGB = cross_val_score(xgb_process, X_black_LR, y_black_LR, cv=kf, scoring='accuracy')\n",
        "accuracy_black_XGB = round(np.average(kfscore_accuracy_black_XGB) * 100, 2)\n",
        "print('Accuracy for Black people:', accuracy_black_XGB)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_black_XGB_std = round(np.std(kfscore_accuracy_black_XGB) * 100, 2)\n",
        "table_black_XGB = str(accuracy_black_XGB) + ' [+/-' + str(accuracy_black_XGB_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_black_XGB = cross_val_predict(xgb_process, X_black_LR, y_black_LR, cv=kf)\n",
        "conf_mat_black_XGB = confusion_matrix(y_black_LR, y_pred_black_XGB, normalize='true')\n",
        "FP_black_XGB = round(conf_mat_black_XGB[0,1] * 100, 2)\n",
        "FN_black_XGB = round(conf_mat_black_XGB[1,0] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_XGB)\n",
        "print('False Negative for Black people:',  FN_black_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard deviation for Black accuracy: 0.47\n"
          ]
        }
      ],
      "source": [
        "print('Standard deviation for Black accuracy:', accuracy_black_XGB_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Caucasian people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for White people: 99.35\n",
            "False Positive for White people: 0.81\n",
            "False Negative for White people: 0.41\n"
          ]
        }
      ],
      "source": [
        "# dataset for White people\n",
        "df_white_XGB = df_compas.loc[df_compas['race'] == 'Caucasian']\n",
        "\n",
        "# splitting the data\n",
        "X_white_XGB = df_white_XGB.drop(columns='two_year_recid')\n",
        "y_white_XGB = df_white_XGB['two_year_recid']\n",
        "\n",
        "# sort data into numerical and categorical columns\n",
        "numerical_cols = X_white_XGB.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = X_white_XGB.select_dtypes(include=['object']).columns\n",
        "\n",
        "# accuracy\n",
        "kfscore_accuracy_white_XGB = cross_val_score(xgb_process, X_white_XGB, y_white_XGB, cv=kf, scoring='accuracy')\n",
        "accuracy_white_XGB = round(np.average(kfscore_accuracy_white_XGB) * 100, 2)\n",
        "print('Accuracy for White people:', accuracy_white_XGB)\n",
        "\n",
        "# standard deviation\n",
        "accuracy_white_XGB_std = round(np.std(kfscore_accuracy_overall_XGB) * 100, 2)\n",
        "table_white_XGB = str(accuracy_overall_XGB) + ' [+/-' + str(accuracy_overall_XGB_std) + ']'\n",
        "\n",
        "# false positive and false negative\n",
        "y_pred_white_XGB = cross_val_predict(xgb_process, X_white_XGB, y_white_XGB, cv=kf)\n",
        "conf_mat_white_XGB = confusion_matrix(y_white_XGB, y_pred_white_XGB, normalize='true')\n",
        "FP_white_XGB = round(conf_mat_white_XGB[0,1] * 100, 2)\n",
        "FN_white_XGB = round(conf_mat_white_XGB[1,0] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_XGB)\n",
        "print('False Negative for White people:', FN_white_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard deviation for White accuracy: 0.39\n"
          ]
        }
      ],
      "source": [
        "print('Standard deviation for White accuracy:',accuracy_white_XGB_std) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckUkz8rF4DCS"
      },
      "source": [
        "#### Logistic Regression with RandomizedSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1BbONsj1an6",
        "outputId": "149e59c0-6a62-48cb-fdef-9a7a099ca025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of the F1-score: 60.33\n",
            "Standard deviation of the F1-score: 2.08\n",
            "False Positive for Black people: 37.72\n",
            "False Negative for Black people: 28.67\n",
            "False Positive for White people: 11.29\n",
            "False Negative for White people: 65.42\n"
          ]
        }
      ],
      "source": [
        "# beginning parameters for tuning are from the articles in Level Up Coding, Toward Data Science and StackOverflow\n",
        "# the default solver of the logistic regression is 'lbfgs'. In order to compare it to the previous results with LR this is not changed.\n",
        "# param = {\n",
        "#     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "#     'penalty': ['l2', None],\n",
        "#     'solver': ['lbfgs'], \n",
        "#     'max_iter': [1000, 1500, 2000, 2500, 3000],\n",
        "# }\n",
        "\n",
        "# parameters\n",
        "param_lr_rs = {\n",
        "    'C': [100],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs'], # the default solver of the logistic regression is 'lbfgs'. In order to compare it to the previous results with LR this is not changed.\n",
        "    'max_iter': [1000],\n",
        "}\n",
        "\n",
        "# model\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# random search and tuning\n",
        "random_search_lr = RandomizedSearchCV(lr, param_distributions=param_lr_rs, scoring='f1', cv=kf, n_iter=1)\n",
        "random_search_lr.fit(X_overall_LR8, y_overall_LR8)\n",
        "\n",
        "# F1-score\n",
        "F1_mean_lr_rs = round(np.mean(random_search_lr.score(X_overall_LR8, y_overall_LR8)) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_lr_rs)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_lr_rs = random_search_lr.cv_results_['std_test_score']\n",
        "F1_std_lr_rs_rounded = round(F1_std_lr_rs[0] * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_lr_rs_rounded)\n",
        "\n",
        "# false positive and false negative for Black dataset\n",
        "y_pred_black_lr_rs = cross_val_predict(random_search_lr, X_black_LR8, y_black_LR8, cv=kf)\n",
        "conf_mat_black_lr_rs = confusion_matrix(y_black_LR8, y_pred_black_lr_rs, normalize='true')\n",
        "FP_black_lr_rs = round(conf_mat_black_lr_rs[0,1] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_lr_rs)\n",
        "FN_black_lr_rs = round(conf_mat_black_lr_rs[1,0] * 100, 2)\n",
        "print('False Negative for Black people:', FN_black_lr_rs)\n",
        "\n",
        "# false positive and false negative for White dataset\n",
        "y_pred_white_lr_rs = cross_val_predict(random_search_lr, X_white_LR8, y_white_LR8, cv=kf)\n",
        "conf_mat_white_lr_rs = confusion_matrix(y_white_LR8, y_pred_white_lr_rs, normalize='true')\n",
        "FP_white_lr_rs = round(conf_mat_white_lr_rs[0,1] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_lr_rs)\n",
        "FN_white_lr_rs = round(conf_mat_white_lr_rs[1,0] * 100, 2)\n",
        "print('False Negative for White people:', FN_white_lr_rs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWLnQEM_4MhO"
      },
      "source": [
        "#### Logistic Regression with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4xo1wctY9H-",
        "outputId": "a7065f4e-3772-4da9-d35b-f51f6dd9fa28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of the F1-score: 60.33\n",
            "Standard deviation of the F1-score: 2.07\n",
            "False Positive for Black people: 37.77\n",
            "False Negative for Black people: 28.67\n",
            "False Positive for White people: 11.29\n",
            "False Negative for White people: 65.42\n"
          ]
        }
      ],
      "source": [
        "# beginning parameters for tuning are from the articles in Level Up Coding, Toward Data Science and StackOverflow\n",
        "# the default solver of the logistic regression is 'lbfgs'. In order to compare it to the previous results with LR this is not changed.\n",
        "# param = {\n",
        "#     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "#     'penalty': ['l2', None],\n",
        "#     'solver': ['lbfgs'], \n",
        "#     'max_iter': [1000, 1500, 2000, 2500, 3000],\n",
        "# }\n",
        "\n",
        "# parameters\n",
        "param_lr_gs = {\n",
        "    'C': [1000],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs'], # the default solver of the logistic regression is 'lbfgs'. In order to compare it to the previous results with LR this is not changed.\n",
        "    'max_iter': [1000],\n",
        "}\n",
        "\n",
        "# model\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# grid search and tuning\n",
        "grid_search_lr = GridSearchCV(lr, param_grid=param_lr_gs, scoring='f1', cv=kf, n_jobs=-1)\n",
        "grid_search_lr.fit(X_overall_LR8, y_overall_LR8)\n",
        "\n",
        "# F1-score\n",
        "F1_mean_lr_gs = round(np.mean(grid_search_lr.score(X_overall_LR8, y_overall_LR8)) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_lr_gs)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_lr_gs = grid_search_lr.cv_results_['std_test_score']\n",
        "F1_std_lr_gs_rounded = round(F1_std_lr_gs[0] * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_lr_gs_rounded)\n",
        "\n",
        "# false positive and false negative for Black dataset\n",
        "y_pred_black_lr_gs = cross_val_predict(grid_search_lr, X_black_LR8, y_black_LR8, cv=kf)\n",
        "conf_mat_black_lr_gs = confusion_matrix(y_black_LR8, y_pred_black_lr_gs, normalize='true')\n",
        "FP_black_lr_gs = round(conf_mat_black_lr_gs[0,1] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_lr_gs)\n",
        "FN_black_lr_gs = round(conf_mat_black_lr_gs[1,0] * 100, 2)\n",
        "print('False Negative for Black people:', FN_black_lr_gs)\n",
        "\n",
        "# false positive and false negative for White dataset\n",
        "y_pred_white_lr_gs = cross_val_predict(grid_search_lr, X_white_LR8, y_white_LR8, cv=kf)\n",
        "conf_mat_white_lr_gs = confusion_matrix(y_white_LR8, y_pred_white_lr_gs, normalize='true')\n",
        "FP_white_lr_gs = round(conf_mat_white_lr_gs[0,1] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_lr_gs)\n",
        "FN_white_lr_gs = round(conf_mat_white_lr_gs[1,0] * 100, 2)\n",
        "print('False Negative for White people:', FN_white_lr_gs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cHTPRzhtNBK"
      },
      "source": [
        "#### Grid Search with Logistic Regression and Fairlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVbc7V-ltNfJ",
        "outputId": "0dbf250c-4bc8-4652-a4f2-58683b520169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of the Accuracy: 65.89\n",
            "Mean of the F1-score: 57.21\n",
            "Standard deviation of the F1-score: 2.84\n",
            "False Positive for Black people: 37.66\n",
            "False Negative for Black people: 28.88\n",
            "False Positive for White people: 11.42\n",
            "False Negative for White people: 65.53\n"
          ]
        }
      ],
      "source": [
        "from fairlearn.preprocessing import CorrelationRemover\n",
        "\n",
        "# transforming the data with the correlation remover\n",
        "cr = CorrelationRemover(sensitive_feature_ids=['race'])\n",
        "X_overall_fairlearn = cr.fit_transform(X_overall_LR8)\n",
        "\n",
        "# beginning parameters for tuning are from the articles in Level Up Coding, Toward Data Science and StackOverflow\n",
        "# the default solver of the logistic regression is 'lbfgs'. In order to compare it to the previous results with LR this is not changed.\n",
        "# param = {\n",
        "#     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "#     'penalty': ['l2', None],\n",
        "#     'solver': ['lbfgs'], \n",
        "#     'max_iter': [1000, 1500, 2000, 2500, 3000],\n",
        "# }\n",
        "\n",
        "# parameters\n",
        "param_lr_gs_cr = {\n",
        "    'C': [0.1],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs'],\n",
        "    'max_iter': [1000],\n",
        "}\n",
        "\n",
        "# model\n",
        "lr_gs_cr = LogisticRegression(**param_lr_gs_cr)\n",
        "\n",
        "# grid search and tuning\n",
        "grid_search_lr_cr = GridSearchCV(lr_gs_cr, param_grid=param_lr_gs_cr, scoring='f1', cv=kf, n_jobs=-1)\n",
        "grid_search_lr_cr.fit(X_overall_fairlearn, y_overall_LR8)\n",
        "\n",
        "# Accuracy\n",
        "grid_search_lr_cr_acc = GridSearchCV(lr_gs_cr, param_grid=param_lr_gs_cr, scoring='accuracy', cv=kf, n_jobs=-1)\n",
        "grid_search_lr_cr_acc.fit(X_overall_fairlearn, y_overall_LR8)\n",
        "acc_mean_lr_gs_cr = round(np.mean(grid_search_lr_cr_acc.score(X_overall_fairlearn, y_overall_LR8)) * 100, 2)\n",
        "print('Mean of the Accuracy:', acc_mean_lr_gs_cr)\n",
        "\n",
        "# F1-score\n",
        "F1_mean_lr_gs_cr = round(np.mean(grid_search_lr_cr.score(X_overall_fairlearn, y_overall_LR8)) * 100, 2)\n",
        "print('Mean of the F1-score:', F1_mean_lr_gs_cr)\n",
        "\n",
        "# standard deviation of the F1-score\n",
        "F1_std_lr_gs_cr = grid_search_lr_cr.cv_results_['std_test_score']\n",
        "F1_std_lr_gs_cr_rounded = round(F1_std_lr_gs_cr[0] * 100, 2)\n",
        "print('Standard deviation of the F1-score:', F1_std_lr_gs_cr_rounded)\n",
        "\n",
        "# false positive and false negative for Black dataset\n",
        "X_black_lr_fairlearn = cr.fit_transform(X_black_LR8)\n",
        "y_pred_black_lr_gs_cr = cross_val_predict(grid_search_lr_cr, X_black_lr_fairlearn, y_black_LR8, cv=kf)\n",
        "conf_mat_black_lr_gs_cr = confusion_matrix(y_black_LR8, y_pred_black_lr_gs_cr, normalize='true')\n",
        "FP_black_lr_gs_cr = round(conf_mat_black_lr_gs_cr[0,1] * 100, 2)\n",
        "print('False Positive for Black people:', FP_black_lr_gs_cr)\n",
        "FN_black_lr_gs_cr = round(conf_mat_black_lr_gs_cr[1,0] * 100, 2)\n",
        "print('False Negative for Black people:', FN_black_lr_gs_cr)\n",
        "\n",
        "# false positive and false negative for White dataset\n",
        "X_white_lr_fairlearn = cr.fit_transform(X_white_LR8)\n",
        "y_pred_white_lr_gs_cr = cross_val_predict(grid_search_lr_cr, X_white_lr_fairlearn, y_white_LR8, cv=kf)\n",
        "conf_mat_white_lr_gs_cr = confusion_matrix(y_white_LR8, y_pred_white_lr_gs_cr, normalize='true')\n",
        "FP_white_lr_gs_cr = round(conf_mat_white_lr_gs_cr[0,1] * 100, 2)\n",
        "print('False Positive for White people:', FP_white_lr_gs_cr)\n",
        "FN_white_lr_gs_cr = round(conf_mat_white_lr_gs_cr[1,0] * 100, 2)\n",
        "print('False Negative for White people:', FN_white_lr_gs_cr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2VkuHChxomC"
      },
      "source": [
        "# Statistical Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1T1Bm7Byni5"
      },
      "source": [
        "#### Mann-Whitney U test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8qFGpgmiF1A",
        "outputId": "bdd624dd-f6a5-4346-ddde-51b060ae095a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "U statistic:  86.0\n",
            "P-value:  0.007262595901896159\n",
            "Reject the null hypothesis: Different distribution.\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# create arrays\n",
        "f1_scores_xgb = []\n",
        "f1_scores_lr = []\n",
        "\n",
        "# for each fold append the F1-score\n",
        "for i in range(kf.get_n_splits()):\n",
        "    f1_scores_xgb.append(grid_search_cr.cv_results_[f'split{i}_test_score'])\n",
        "    f1_scores_lr.append(grid_search_lr_cr.cv_results_[f'split{i}_test_score'])\n",
        "\n",
        "# flattening the list so it is only one array\n",
        "f1_scores_xgb = [item for sublist in f1_scores_xgb for item in sublist]\n",
        "f1_scores_lr = [item for sublist in f1_scores_lr for item in sublist]\n",
        "\n",
        "# mann-whitney u test\n",
        "statistics_mwu, pvalue_mwu = mannwhitneyu(f1_scores_xgb, f1_scores_lr, alternative='two-sided')\n",
        "\n",
        "# print results\n",
        "print(\"U statistic: \", statistics_mwu)\n",
        "print(\"P-value: \", pvalue_mwu)\n",
        "\n",
        "# interpretation\n",
        "alpha = 0.05\n",
        "if pvalue_mwu < alpha:\n",
        "    print(\"Reject the null hypothesis: Different distribution.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: Same distribution.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-TSOlej9B6Y"
      },
      "source": [
        "#### ttest_ind_from_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7133BxfQAadE",
        "outputId": "a6014ab1-ac2e-49a2-dc39-9eaa56d791e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T-statistic:  [616.74690187]\n",
            "P-value:  [2.20610556e-40]\n",
            "Reject the null hypothesis: average values of two samples are not identical.\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_ind_from_stats\n",
        "\n",
        "# ttest_ind_from_stats test\n",
        "statistics_tt, pvalue_tt = ttest_ind_from_stats(F1_mean_gs_cr, F1_std_gs_cr, 10, F1_mean_lr_gs_cr, F1_std_lr_gs_cr, 10, equal_var=True, alternative='two-sided')\n",
        "\n",
        "# print results\n",
        "print(\"T-statistic: \", statistics_tt)\n",
        "print(\"P-value: \", pvalue_tt)\n",
        "\n",
        "# interpretation\n",
        "alpha = 0.05\n",
        "if pvalue_tt < alpha:\n",
        "    print(\"Reject the null hypothesis: average values of two samples are not identical.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: average values of two samples are identical.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi6eZB13iF1F"
      },
      "source": [
        "Sources:\n",
        "\n",
        "Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In Proceedings of\n",
        "the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 785â€“794). Association for Computing Machinery. https://doi.org/10.1145/2939672.2939785\n",
        "\n",
        "Dressel, A. & Farid, H. (2018). The accuracy, fairness, and limits of predicting recidivism. Science Advances, 4 (1), eaao5580. https://doi.org/10.1126/sciadv.aao5580\n",
        "\n",
        "Geeks for Geeks. (2022). How to make a table in Python?. https://www.geeksforgeeks.org/how-to-make-a-table-in-python/\n",
        "\n",
        "Group, M. (21.05.2023). A Comprehensive Analysis of Hyperparameter Optimization in Logistic Regression Models. Level Up Coding. https://levelup.gitconnected.com/a-comprehensive-analysis-of-hyperparameter-optimization-in-logistic-regression-models-521564c1bfc0\\\n",
        "\n",
        "Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., \n",
        "Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., FernÃ¡ndez del RÃ­o, J., Wiebe, M., Peterson, P., â€¦ Oliphant, T. E. (2020). Array programming with NumPy. Nature, 585, 357-362. https://doi.org/10.1038/s41586-020-2649-2\n",
        "\n",
        "Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M.,\n",
        "Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825-2830. https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html\n",
        "\n",
        "Qiao, F. (08.01.2019). Logistic Regression Model Tuning with scikit-learn â€” Part 1: Comparison of metrics along the model tuning process. Towards Data Science.\n",
        "https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n",
        "\n",
        "RegenerativeToday. (18.05.2022). Step by Step Tutorial on Logistic Regression in Python | sklearn |Jupyter Notebook [Video]. Youtube. https://www.youtube.com/watch?v=bSXIbCZNBw0\n",
        "\n",
        "Ryan Nolan Data. (28.08.2023). A Comprehensive Guide to Cross-Validation with Scikit-Learn and Python [Video]. Youtube. https://www.youtube.com/watch?v=glLNo1ZnmPA&list=PLcQVY5V2UY4LNmObS0gqNVyNdVfXnHwu8&index=14\n",
        "\n",
        "Scikit-Learn. (n.d.). User Guide. https://scikit-learn.org/stable/user_guide.html\n",
        "\n",
        "Scikit-Learn. (n.d.). API Reference. https://scikit-learn.org/stable/api/index.html\n",
        "\n",
        "SciPy. (n.d.). User Guide. https://docs.scipy.org/doc/scipy/tutorial/index.html\n",
        "\n",
        "SciPy. (n.d.). API Reference. https://docs.scipy.org/doc/scipy/reference/index.html\n",
        "\n",
        "Stackoverflow. (2014). Fine-tuning parameters in Logistic Regression. https://stackoverflow.com/questions/21816346/fine-tuning-parameters-in-logistic-regression\n",
        "\n",
        "Stackoverflow. (2014). How does the list comprehension to flatten a python list work? [duplicate]. https://stackoverflow.com/questions/25674169/how-does-the-list-comprehension-to-flatten-a-python-list-work\n",
        "\n",
        "Stackoverflow. (2016). Python's tabulate number of decimal. https://stackoverflow.com/questions/37079957/pythons-tabulate-number-of-decimal\n",
        "\n",
        "Stackoverflow. (2018). How can I standardize only numeric variables in an sklearn pipeline?. https://stackoverflow.com/questions/48673402/how-can-i-standardize-only-numeric-variables-in-an-sklearn-pipeline\n",
        "\n",
        "Stackoverflow.(2018). getting the confusion matrix for each cross validation fold. https://stackoverflow.com/questions/49587820/getting-the-confusion-matrix-for-each-cross-validation-fold\n",
        "\n",
        "The pandas development team. (2024). pandas-dev/pandas: Pandas (v2.2.2). Zenodo.\n",
        "https://doi.org/10.5281/zenodo.10957263\n",
        "\n",
        "Velarde, G., Weichert, M., Deshmunkh, A., Deshmane, S., Sudhir, A., Sharma, K. & Joshi, V. (2024). Tree boosting methods for balanced and imbalanced classification and their robustness over time in risk assessment. Intelligent Systems with Applications. 22, 200354. https://doi.org/10.1016/j.iswa.2024.200354\n",
        "\n",
        "Virtanen, P., Gommers, R., Oliphant, T. E., Haberland, M., Reddy, T., Cournapeau, D., Burovski,\n",
        "E., Peterson, P., Weckesser, W., Bright, J., van der Walt, S. J., Brett, M., Wilson, J., Millman, K. J., Mayorov, N., Nelson, A. R. J., Jones, E., Kern, R., Larson, E., Carey, CJ, â€¦ SciPy 1.0 Contributors (2020). SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17(3), 261-272. https://doi.org/10.1038/s41592-019-0686-2\n",
        "\n",
        "Weerts, H., DudÃ­k, M., Edgar, R., Jalali, A., Lutz, R. & Madaio, M. (2023). Fairlearn: Assessing and Improving Fairness of AI Systems. Journal of Machine Learning Research, 24 (257), 1-8. http://jmlr.org/papers/v24/23-0389.html\n",
        "\n",
        "Weerts, H. (19.06.2024). An Introduction to Responsible Machine Learning. GitHub. https://hildeweerts.github.io/responsiblemachinelearning/index.html"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
