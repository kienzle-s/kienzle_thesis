{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with 7 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7214 entries, 0 to 7213\n",
      "Data columns (total 53 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       7214 non-null   int64  \n",
      " 1   name                     7214 non-null   object \n",
      " 2   first                    7214 non-null   object \n",
      " 3   last                     7214 non-null   object \n",
      " 4   compas_screening_date    7214 non-null   object \n",
      " 5   sex                      7214 non-null   object \n",
      " 6   dob                      7214 non-null   object \n",
      " 7   age                      7214 non-null   int64  \n",
      " 8   age_cat                  7214 non-null   object \n",
      " 9   race                     7214 non-null   object \n",
      " 10  juv_fel_count            7214 non-null   int64  \n",
      " 11  decile_score             7214 non-null   int64  \n",
      " 12  juv_misd_count           7214 non-null   int64  \n",
      " 13  juv_other_count          7214 non-null   int64  \n",
      " 14  priors_count             7214 non-null   int64  \n",
      " 15  days_b_screening_arrest  6907 non-null   float64\n",
      " 16  c_jail_in                6907 non-null   object \n",
      " 17  c_jail_out               6907 non-null   object \n",
      " 18  c_case_number            7192 non-null   object \n",
      " 19  c_offense_date           6055 non-null   object \n",
      " 20  c_arrest_date            1137 non-null   object \n",
      " 21  c_days_from_compas       7192 non-null   float64\n",
      " 22  c_charge_degree          7214 non-null   object \n",
      " 23  c_charge_desc            7185 non-null   object \n",
      " 24  is_recid                 7214 non-null   int64  \n",
      " 25  r_case_number            3471 non-null   object \n",
      " 26  r_charge_degree          3471 non-null   object \n",
      " 27  r_days_from_arrest       2316 non-null   float64\n",
      " 28  r_offense_date           3471 non-null   object \n",
      " 29  r_charge_desc            3413 non-null   object \n",
      " 30  r_jail_in                2316 non-null   object \n",
      " 31  r_jail_out               2316 non-null   object \n",
      " 32  violent_recid            0 non-null      float64\n",
      " 33  is_violent_recid         7214 non-null   int64  \n",
      " 34  vr_case_number           819 non-null    object \n",
      " 35  vr_charge_degree         819 non-null    object \n",
      " 36  vr_offense_date          819 non-null    object \n",
      " 37  vr_charge_desc           819 non-null    object \n",
      " 38  type_of_assessment       7214 non-null   object \n",
      " 39  decile_score.1           7214 non-null   int64  \n",
      " 40  score_text               7214 non-null   object \n",
      " 41  screening_date           7214 non-null   object \n",
      " 42  v_type_of_assessment     7214 non-null   object \n",
      " 43  v_decile_score           7214 non-null   int64  \n",
      " 44  v_score_text             7214 non-null   object \n",
      " 45  v_screening_date         7214 non-null   object \n",
      " 46  in_custody               6978 non-null   object \n",
      " 47  out_custody              6978 non-null   object \n",
      " 48  priors_count.1           7214 non-null   int64  \n",
      " 49  start                    7214 non-null   int64  \n",
      " 50  end                      7214 non-null   int64  \n",
      " 51  event                    7214 non-null   int64  \n",
      " 52  two_year_recid           7214 non-null   int64  \n",
      "dtypes: float64(4), int64(16), object(33)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# loading data and observations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_compas = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "df_compas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>marsha miles</td>\n",
       "      <td>marsha</td>\n",
       "      <td>miles</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>Male</td>\n",
       "      <td>1971-08-22</td>\n",
       "      <td>44</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>2013-11-30</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "5   7        marsha miles  marsha        miles            2013-11-30  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "5  1971-08-22   44          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "5           Low        2013-11-30  2013-11-30   2013-12-01               0   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "5     1   853     0              0  \n",
       "\n",
       "[6 rows x 53 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compas.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
      "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
      "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
      "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
      "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
      "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
      "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
      "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
      "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
      "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
      "       'decile_score.1', 'score_text', 'screening_date',\n",
      "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
      "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
      "       'start', 'end', 'event', 'two_year_recid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_compas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unused columns\n",
    "\n",
    "df_LR7 = df_compas.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
    "       'age_cat', 'race', 'decile_score', 'juv_other_count', \n",
    "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
    "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
    "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
    "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
    "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
    "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
    "       'decile_score.1', 'score_text', 'screening_date',\n",
    "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
    "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
    "       'start', 'end', 'event'])\n",
    "\n",
    "# transforming string values into numerical\n",
    "\n",
    "df_LR7['sex'] = df_LR7['sex'].astype('category')\n",
    "df_LR7['sex'] = df_LR7['sex'].cat.codes\n",
    "\n",
    "df_LR7['c_charge_degree'] = df_LR7['c_charge_degree'].astype('category')\n",
    "df_LR7['c_charge_degree'] = df_LR7['c_charge_degree'].cat.codes\n",
    "\n",
    "df_LR7['c_charge_desc'] = df_LR7['c_charge_desc'].astype('category')\n",
    "df_LR7['c_charge_desc'] = df_LR7['c_charge_desc'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                0\n",
       "age                0\n",
       "juv_fel_count      0\n",
       "juv_misd_count     0\n",
       "priors_count       0\n",
       "c_charge_degree    0\n",
       "c_charge_desc      0\n",
       "two_year_recid     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null values\n",
    "\n",
    "df_LR7.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting of the dataset in features and the variable to predict\n",
    "\n",
    "X_overall_LR7 = df_LR7.drop(columns='two_year_recid')\n",
    "y_overall_LR7 = df_LR7['two_year_recid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.58\n",
      "0.6\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=28)\n",
    "\n",
    "# accuracy\n",
    "kfscore_accuracy_overall_LR7 = cross_val_score(lr, X_overall_LR7, y_overall_LR7, cv=kf, scoring='accuracy')\n",
    "accuracy_overall_LR7 = round(np.average(kfscore_accuracy_overall_LR7) * 100, 2)\n",
    "print(accuracy_overall_LR7)\n",
    "\n",
    "accuracy_overall_LR7_std = round(np.std(kfscore_accuracy_overall_LR7) * 100, 2)\n",
    "\n",
    "table_overall_LR7 = str(accuracy_overall_LR7) + ' [+/-' + str(accuracy_overall_LR7_std) + ']'\n",
    "\n",
    "# F1-score\n",
    "kfscore_f1_overall_LR7 = cross_val_score(lr, X_overall_LR7, y_overall_LR7, cv=kf, scoring='f1')\n",
    "F1_mean_LR7 = round(np.mean(kfscore_f1_overall_LR7), 2)\n",
    "print(F1_mean_LR7)\n",
    "\n",
    "F1_std_LR7 = round(np.std(kfscore_f1_overall_LR7), 2)\n",
    "print(F1_std_LR7)\n",
    "\n",
    "table_F1_LR7 = str(F1_mean_LR7) + ' [+/-' + str(F1_std_LR7) + ']'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### African-American people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.88\n",
      "37.77\n",
      "28.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_black_LR7 = df_compas.loc[df_compas['race'] == \"African-American\"]\n",
    "df_black_LR7 = df_black_LR7.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
    "       'age_cat', 'race', 'decile_score', 'juv_other_count', \n",
    "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
    "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
    "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
    "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
    "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
    "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
    "       'decile_score.1', 'score_text', 'screening_date',\n",
    "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
    "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
    "       'start', 'end', 'event'])\n",
    "\n",
    "df_black_LR7['sex'] = df_black_LR7['sex'].astype('category')\n",
    "df_black_LR7['sex'] = df_black_LR7['sex'].cat.codes\n",
    "df_black_LR7['c_charge_degree'] = df_black_LR7['c_charge_degree'].astype('category')\n",
    "df_black_LR7['c_charge_degree'] = df_black_LR7['c_charge_degree'].cat.codes\n",
    "df_black_LR7['c_charge_desc'] = df_black_LR7['c_charge_desc'].astype('category')\n",
    "df_black_LR7['c_charge_desc'] = df_black_LR7['c_charge_desc'].cat.codes\n",
    "\n",
    "X_black_LR7 = df_black_LR7.drop(columns='two_year_recid')\n",
    "y_black_LR7 = df_black_LR7['two_year_recid']\n",
    "\n",
    "kfscore_accuracy_black_LR7 = cross_val_score(lr, X_black_LR7, y_black_LR7, cv=kf, scoring='accuracy')\n",
    "\n",
    "accuracy_black_LR7 = round(np.average(kfscore_accuracy_black_LR7) * 100, 2)\n",
    "print(accuracy_black_LR7) \n",
    "\n",
    "accuracy_black_LR7_std = round(np.std(kfscore_accuracy_black_LR7) * 100, 2)\n",
    "\n",
    "table_black_LR7 = str(accuracy_black_LR7) + ' [+/-' + str(accuracy_black_LR7_std) + ']'\n",
    "\n",
    "y_pred_black_LR7 = cross_val_predict(lr, X_black_LR7, y_black_LR7, cv=kf)\n",
    "conf_mat_black_LR7 = confusion_matrix(y_black_LR7, y_pred_black_LR7, normalize='true')\n",
    "\n",
    "FP_black_LR7 = round(conf_mat_black_LR7[0,1] * 100, 2)\n",
    "FN_black_LR7 = round(conf_mat_black_LR7[1,0] * 100, 2)\n",
    "\n",
    "print(FP_black_LR7)\n",
    "print(FN_black_LR7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caucasian people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.4\n",
      "11.29\n",
      "65.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_white_LR7 = df_compas.loc[df_compas['race'] == 'Caucasian']\n",
    "df_white_LR7 = df_white_LR7.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
    "       'age_cat', 'race', 'decile_score', 'juv_other_count', \n",
    "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
    "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
    "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
    "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
    "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
    "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
    "       'decile_score.1', 'score_text', 'screening_date',\n",
    "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
    "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
    "       'start', 'end', 'event'])\n",
    "\n",
    "df_white_LR7['sex'] = df_white_LR7['sex'].astype('category')\n",
    "df_white_LR7['sex'] = df_white_LR7['sex'].cat.codes\n",
    "df_white_LR7['c_charge_degree'] = df_white_LR7['c_charge_degree'].astype('category')\n",
    "df_white_LR7['c_charge_degree'] = df_white_LR7['c_charge_degree'].cat.codes\n",
    "df_white_LR7['c_charge_desc'] = df_white_LR7['c_charge_desc'].astype('category')\n",
    "df_white_LR7['c_charge_desc'] = df_white_LR7['c_charge_desc'].cat.codes\n",
    "\n",
    "X_white_LR7 = df_white_LR7.drop(columns='two_year_recid')\n",
    "y_white_LR7 = df_white_LR7['two_year_recid']\n",
    "\n",
    "kfscore_accuracy_white_LR7 = cross_val_score(lr, X_white_LR7, y_white_LR7, cv=kf, scoring='accuracy')\n",
    "\n",
    "accuracy_white_LR7 = round(np.average(kfscore_accuracy_white_LR7) * 100, 2)\n",
    "print(accuracy_white_LR7)\n",
    "\n",
    "accuracy_white_LR7_std = round(np.std(kfscore_accuracy_overall_LR7) * 100, 2)\n",
    "\n",
    "table_white_LR7 = str(accuracy_overall_LR7) + ' [+/-' + str(accuracy_overall_LR7_std) + ']'\n",
    "\n",
    "y_pred_white_LR7 = cross_val_predict(lr, X_white_LR7, y_white_LR7, cv=kf)\n",
    "conf_mat_white_LR7 = confusion_matrix(y_white_LR7, y_pred_white_LR7, normalize='true')\n",
    "\n",
    "FP_white_LR7 = round(conf_mat_white_LR7[0,1] * 100, 2)\n",
    "FN_white_LR7 = round(conf_mat_white_LR7[1,0] * 100, 2)\n",
    "\n",
    "print(FP_white_LR7)\n",
    "print(FN_white_LR7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with 2 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unused columns\n",
    "\n",
    "df_LR2 = df_LR7.drop(columns=['sex', 'c_charge_degree', 'c_charge_desc'])\n",
    "\n",
    "# remove all features except age and the total number of previous convictions\n",
    "\n",
    "df_LR2['total_number'] = df_LR2['juv_fel_count'] + df_LR2['juv_misd_count'] + df_LR2['priors_count']\n",
    "df_LR2 = df_LR2.drop(columns=['juv_fel_count', 'juv_misd_count', 'priors_count'])\n",
    "\n",
    "X_overall_LR2 = df_LR2.drop(columns='two_year_recid')\n",
    "y_overall_LR2 = df_LR2['two_year_recid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.51\n",
      "0.58\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "kfscore_accuracy_overall_LR2 = cross_val_score(lr, X_overall_LR2, y_overall_LR2, cv=kf, scoring='accuracy')\n",
    "accuracy_overall_LR2 = round(np.average(kfscore_accuracy_overall_LR2) * 100, 2)\n",
    "print(accuracy_overall_LR2)\n",
    "\n",
    "accuracy_overall_LR2_std = round(np.std(kfscore_accuracy_overall_LR2) * 100, 2)\n",
    "\n",
    "table_overall_LR2 = str(accuracy_overall_LR2) + ' [+/-' + str(accuracy_overall_LR2_std) + ']'\n",
    "\n",
    "# F1-score\n",
    "kfscore_f1_overall_LR2 = cross_val_score(lr, X_overall_LR2, y_overall_LR2, cv=kf, scoring='f1')\n",
    "F1_mean_LR2 = round(np.mean(kfscore_f1_overall_LR2), 2)\n",
    "print(F1_mean_LR2)\n",
    "\n",
    "F1_std_LR2 = round(np.std(kfscore_f1_overall_LR2), 2)\n",
    "table_F1_LR2 = str(F1_mean_LR2) + ' [+/-' + str(F1_std_LR2) + ']'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### African-American people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.56\n",
      "35.71\n",
      "28.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_black_LR2 = df_black_LR7.drop(columns=['sex', 'c_charge_degree', 'c_charge_desc'])\n",
    "\n",
    "df_black_LR2['total_number'] = df_black_LR2['juv_fel_count'] + df_black_LR2['juv_misd_count'] + df_black_LR2['priors_count']\n",
    "df_black_LR2 = df_black_LR2.drop(columns=['juv_fel_count', 'juv_misd_count', 'priors_count'])\n",
    "\n",
    "X_black_LR2 = df_black_LR2.drop(columns='two_year_recid')\n",
    "y_black_LR2 = df_black_LR2['two_year_recid']\n",
    "\n",
    "kfscore_accuracy_black_LR2 = cross_val_score(lr, X_black_LR2, y_black_LR2, cv=kf, scoring='accuracy')\n",
    "accuracy_black_LR2 = round(np.average(kfscore_accuracy_black_LR2) * 100, 2)\n",
    "print(accuracy_black_LR2)\n",
    "\n",
    "accuracy_black_LR2_std = round(np.std(kfscore_accuracy_black_LR2) * 100, 2)\n",
    "\n",
    "table_black_LR2 = str(accuracy_black_LR2) + ' [+/-' + str(accuracy_black_LR2_std) + ']'\n",
    "\n",
    "y_pred_black_LR2 = cross_val_predict(lr, X_black_LR2, y_black_LR2, cv=10)\n",
    "conf_mat_black_LR2 = confusion_matrix(y_black_LR2, y_pred_black_LR2, normalize='true')\n",
    "\n",
    "FP_black_LR2 = round(conf_mat_black_LR2[0,1] * 100, 2)\n",
    "FN_black_LR2 = round(conf_mat_black_LR2[1,0] * 100, 2)\n",
    "\n",
    "print(FP_black_LR2)\n",
    "print(FN_black_LR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caucasian people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.97\n",
      "10.48\n",
      "65.32\n"
     ]
    }
   ],
   "source": [
    "df_white_LR2 = df_white_LR7.drop(columns=['sex', 'c_charge_degree', 'c_charge_desc'])\n",
    "\n",
    "df_white_LR2['total_number'] = df_white_LR2['juv_fel_count'] + df_white_LR2['juv_misd_count'] + df_white_LR2['priors_count']\n",
    "df_white_LR2 = df_white_LR2.drop(columns=['juv_fel_count', 'juv_misd_count', 'priors_count'])\n",
    "\n",
    "X_white_LR2 = df_white_LR2.drop(columns='two_year_recid')\n",
    "y_white_LR2 = df_white_LR2['two_year_recid']\n",
    "\n",
    "kfscore_accuracy_white_LR2 = cross_val_score(lr, X_white_LR2, y_white_LR2, cv=kf, scoring='accuracy')\n",
    "accuracy_white_LR2 = round(np.average(kfscore_accuracy_white_LR2) * 100, 2)\n",
    "print(accuracy_white_LR2)\n",
    "\n",
    "accuracy_white_LR2_std = round(np.std(kfscore_accuracy_overall_LR2) * 100, 2)\n",
    "\n",
    "table_white_LR2 = str(accuracy_white_LR2) + ' [+/-' + str(accuracy_white_LR2_std) + ']'\n",
    "\n",
    "y_pred_white_LR2 = cross_val_predict(lr, X_white_LR2, y_white_LR2, cv=10)\n",
    "conf_mat_white_LR2 = confusion_matrix(y_white_LR2, y_pred_white_LR2, normalize='true')\n",
    "\n",
    "FP_white_LR2 = round(conf_mat_white_LR2[0,1] * 100, 2)\n",
    "FN_white_LR2 = round(conf_mat_white_LR2[1,0] * 100, 2)\n",
    "\n",
    "print(FP_white_LR2)\n",
    "print(FN_white_LR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Support Vector Machine with radial basis kernel and 7 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.84\n",
      "0.5\n",
      "61.2\n",
      "61.74\n",
      "37.77\n",
      "28.72\n",
      "11.29\n",
      "65.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "# accuracy\n",
    "kfscore_accuracy_overall_SVM = cross_val_score(svm, X_overall_LR7, y_overall_LR7, cv=kf, scoring='accuracy')\n",
    "accuracy_overall_SVM = round(np.average(kfscore_accuracy_overall_SVM) * 100, 2)\n",
    "print(accuracy_overall_SVM)\n",
    "\n",
    "#standard deviation\n",
    "accuracy_overall_SVM_std = round(np.std(kfscore_accuracy_overall_SVM) * 100, 2)\n",
    "\n",
    "table_overall_SVM = str(accuracy_overall_SVM) + ' [+/-' + str(accuracy_overall_SVM_std) + ']'\n",
    "\n",
    "# F1-score\n",
    "kfscore_f1_overall_SVM = cross_val_score(svm, X_overall_LR7, y_overall_LR7, cv=kf, scoring='f1')\n",
    "F1_mean_SVM = round(np.mean(kfscore_f1_overall_SVM), 2)\n",
    "print(F1_mean_SVM)\n",
    "\n",
    "F1_std_SVM = round(np.std(kfscore_f1_overall_SVM), 2)\n",
    "table_F1_SVM = str(F1_mean_SVM) + ' [+/-' + str(F1_std_SVM) + ']'\n",
    "\n",
    "# accuracy black\n",
    "kfscore_accuracy_black_SVM = cross_val_score(svm, X_black_LR7, y_black_LR7, cv=kf, scoring='accuracy')\n",
    "\n",
    "accuracy_black_SVM = round(np.average(kfscore_accuracy_black_SVM) * 100, 2)\n",
    "print(accuracy_black_SVM)\n",
    "\n",
    "#standard deviation black\n",
    "accuracy_black_SVM_std = round(np.std(kfscore_accuracy_black_SVM) * 100, 2)\n",
    "\n",
    "table_black_SVM = str(accuracy_black_SVM) + ' [+/-' + str(accuracy_black_SVM_std) + ']'\n",
    "\n",
    "# accuracy white\n",
    "kfscore_accuracy_white_SVM = cross_val_score(svm, X_white_LR7, y_white_LR7, cv=kf, scoring='accuracy')\n",
    "\n",
    "accuracy_white_SVM = round(np.average(kfscore_accuracy_white_SVM) * 100, 2)\n",
    "print(accuracy_white_SVM)\n",
    "\n",
    "#standard deviation white\n",
    "accuracy_white_SVM_std = round(np.std(kfscore_accuracy_white_SVM) * 100, 2)\n",
    "\n",
    "table_white_SVM = str(accuracy_white_SVM) + ' [+/-' + str(accuracy_white_SVM_std) + ']'\n",
    "\n",
    "# false positive and negative black\n",
    "y_pred_black_SVM = cross_val_predict(svm, X_black_LR7, y_black_LR7, cv=kf)\n",
    "conf_mat_black_SVM = confusion_matrix(y_black_LR7, y_pred_black_LR7, normalize='true')\n",
    "\n",
    "FP_black_SVM = round(conf_mat_black_SVM[0,1] * 100, 2)\n",
    "FN_black_SVM = round(conf_mat_black_SVM[1,0] * 100, 2)\n",
    "\n",
    "print(FP_black_SVM)\n",
    "print(FN_black_SVM)\n",
    "\n",
    "# false positive and negative white\n",
    "y_pred_white_SVM = cross_val_predict(svm, X_white_LR7, y_white_LR7, cv=kf)\n",
    "conf_mat_white_SVM = confusion_matrix(y_white_LR7, y_pred_white_LR7, normalize='true')\n",
    "\n",
    "FP_white_SVM = round(conf_mat_white_SVM[0,1] * 100, 2)\n",
    "FN_white_SVM = round(conf_mat_white_SVM[1,0] * 100, 2)\n",
    "\n",
    "print(FP_white_SVM)\n",
    "print(FN_white_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with 8 features (including race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.74\n",
      "0.6\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "df_LR8 = df_compas.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
    "       'age_cat', 'decile_score', 'juv_other_count', \n",
    "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
    "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
    "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
    "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
    "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
    "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
    "       'decile_score.1', 'score_text', 'screening_date',\n",
    "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
    "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
    "       'start', 'end', 'event'])\n",
    "\n",
    "# transforming string values into numerical\n",
    "\n",
    "df_LR8['sex'] = df_LR8['sex'].astype('category')\n",
    "df_LR8['sex'] = df_LR8['sex'].cat.codes\n",
    "\n",
    "df_LR8['c_charge_degree'] = df_LR8['c_charge_degree'].astype('category')\n",
    "df_LR8['c_charge_degree'] = df_LR8['c_charge_degree'].cat.codes\n",
    "\n",
    "df_LR8['c_charge_desc'] = df_LR8['c_charge_desc'].astype('category')\n",
    "df_LR8['c_charge_desc'] = df_LR8['c_charge_desc'].cat.codes\n",
    "\n",
    "df_LR8['race'] = df_LR8['race'].astype('category')\n",
    "df_LR8['race'] = df_LR8['race'].cat.codes\n",
    "\n",
    "\n",
    "# splitting of the dataset in features and the variable to predict\n",
    "\n",
    "X_overall_LR8 = df_LR8.drop(columns='two_year_recid')\n",
    "y_overall_LR8 = df_LR8['two_year_recid']\n",
    "\n",
    "# accuracy\n",
    "kfscore_accuracy_overall_LR8 = cross_val_score(lr, X_overall_LR8, y_overall_LR8, cv=kf, scoring='accuracy')\n",
    "accuracy_overall_LR8 = round(np.average(kfscore_accuracy_overall_LR8) * 100, 2)\n",
    "print(accuracy_overall_LR8)\n",
    "\n",
    "accuracy_overall_LR8_std = round(np.std(kfscore_accuracy_overall_LR8) * 100, 2)\n",
    "\n",
    "table_overall_LR8 = str(accuracy_overall_LR8) + ' [+/-' + str(accuracy_overall_LR8_std) + ']'\n",
    "\n",
    "# F1-score\n",
    "kfscore_f1_overall_LR8 = cross_val_score(lr, X_overall_LR8, y_overall_LR8, cv=kf, scoring='f1')\n",
    "F1_mean_LR8 = round(np.mean(kfscore_f1_overall_LR8), 2)\n",
    "print(F1_mean_LR8)\n",
    "\n",
    "F1_std_LR8 = round(np.std(kfscore_f1_overall_LR8), 2)\n",
    "print(F1_std_LR8)\n",
    "\n",
    "table_F1_LR8 = str(F1_mean_LR8) + ' [+/-' + str(F1_std_LR8) + ']'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### African-American people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.91\n",
      "37.77\n",
      "28.67\n"
     ]
    }
   ],
   "source": [
    "df_black_LR8 = df_compas.loc[df_compas['race'] == \"African-American\"]\n",
    "df_black_LR8 = df_black_LR8.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
    "       'age_cat', 'decile_score', 'juv_other_count', \n",
    "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
    "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
    "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
    "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
    "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
    "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
    "       'decile_score.1', 'score_text', 'screening_date',\n",
    "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
    "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
    "       'start', 'end', 'event'])\n",
    "\n",
    "df_black_LR8['sex'] = df_black_LR8['sex'].astype('category')\n",
    "df_black_LR8['sex'] = df_black_LR8['sex'].cat.codes\n",
    "\n",
    "df_black_LR8['c_charge_degree'] = df_black_LR8['c_charge_degree'].astype('category')\n",
    "df_black_LR8['c_charge_degree'] = df_black_LR8['c_charge_degree'].cat.codes\n",
    "\n",
    "df_black_LR8['c_charge_desc'] = df_black_LR8['c_charge_desc'].astype('category')\n",
    "df_black_LR8['c_charge_desc'] = df_black_LR8['c_charge_desc'].cat.codes\n",
    "\n",
    "df_black_LR8['race'] = df_black_LR8['race'].astype('category')\n",
    "df_black_LR8['race'] = df_black_LR8['race'].cat.codes\n",
    "\n",
    "\n",
    "X_black_LR8 = df_black_LR8.drop(columns='two_year_recid')\n",
    "y_black_LR8 = df_black_LR8['two_year_recid']\n",
    "\n",
    "kfscore_accuracy_black_LR8 = cross_val_score(lr, X_black_LR8, y_black_LR8, cv=kf, scoring='accuracy')\n",
    "\n",
    "accuracy_black_LR8 = round(np.average(kfscore_accuracy_black_LR8) * 100, 2)\n",
    "print(accuracy_black_LR8) \n",
    "\n",
    "accuracy_black_LR8_std = round(np.std(kfscore_accuracy_black_LR8) * 100, 2)\n",
    "\n",
    "table_black_LR8 = str(accuracy_black_LR8) + ' [+/-' + str(accuracy_black_LR8_std) + ']'\n",
    "\n",
    "y_pred_black_LR8 = cross_val_predict(lr, X_black_LR8, y_black_LR8, cv=kf)\n",
    "conf_mat_black_LR8 = confusion_matrix(y_black_LR8, y_pred_black_LR8, normalize='true')\n",
    "\n",
    "FP_black_LR8 = round(conf_mat_black_LR8[0,1] * 100, 2)\n",
    "FN_black_LR8 = round(conf_mat_black_LR8[1,0] * 100, 2)\n",
    "\n",
    "print(FP_black_LR8)\n",
    "print(FN_black_LR8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caucasian people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.4\n",
      "11.29\n",
      "65.42\n"
     ]
    }
   ],
   "source": [
    "df_white_LR8 = df_compas.loc[df_compas['race'] == 'Caucasian']\n",
    "df_white_LR8 = df_white_LR8.drop(columns=['id', 'name', 'first', 'last', 'compas_screening_date', 'dob',\n",
    "       'age_cat', 'decile_score', 'juv_other_count', \n",
    "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
    "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas', 'is_recid', 'r_case_number',\n",
    "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
    "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
    "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
    "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
    "       'decile_score.1', 'score_text', 'screening_date',\n",
    "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
    "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
    "       'start', 'end', 'event'])\n",
    "\n",
    "df_white_LR8['sex'] = df_white_LR8['sex'].astype('category')\n",
    "df_white_LR8['sex'] = df_white_LR8['sex'].cat.codes\n",
    "\n",
    "df_white_LR8['c_charge_degree'] = df_white_LR8['c_charge_degree'].astype('category')\n",
    "df_white_LR8['c_charge_degree'] = df_white_LR8['c_charge_degree'].cat.codes\n",
    "\n",
    "df_white_LR8['c_charge_desc'] = df_white_LR8['c_charge_desc'].astype('category')\n",
    "df_white_LR8['c_charge_desc'] = df_white_LR8['c_charge_desc'].cat.codes\n",
    "\n",
    "df_white_LR8['race'] = df_white_LR8['race'].astype('category')\n",
    "df_white_LR8['race'] = df_white_LR8['race'].cat.codes\n",
    "\n",
    "X_white_LR8 = df_white_LR8.drop(columns='two_year_recid')\n",
    "y_white_LR8 = df_white_LR8['two_year_recid']\n",
    "\n",
    "kfscore_accuracy_white_LR8 = cross_val_score(lr, X_white_LR8, y_white_LR8, cv=kf, scoring='accuracy')\n",
    "\n",
    "accuracy_white_LR8 = round(np.average(kfscore_accuracy_white_LR8) * 100, 2)\n",
    "print(accuracy_white_LR8)\n",
    "\n",
    "accuracy_white_LR8_std = round(np.std(kfscore_accuracy_overall_LR8) * 100, 2)\n",
    "\n",
    "table_white_LR8 = str(accuracy_overall_LR8) + ' [+/-' + str(accuracy_overall_LR8_std) + ']'\n",
    "\n",
    "y_pred_white_LR8 = cross_val_predict(lr, X_white_LR8, y_white_LR8, cv=kf)\n",
    "conf_mat_white_LR8 = confusion_matrix(y_white_LR8, y_pred_white_LR8, normalize='true')\n",
    "\n",
    "FP_white_LR8 = round(conf_mat_white_LR8[0,1] * 100, 2)\n",
    "FN_white_LR8 = round(conf_mat_white_LR8[1,0] * 100, 2)\n",
    "\n",
    "print(FP_white_LR8)\n",
    "print(FN_white_LR8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "X_overall_LR = df_compas.drop(columns='two_year_recid')\n",
    "y_overall_LR = df_compas['two_year_recid']\n",
    "\n",
    "numerical_cols = X_overall_LR.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X_overall_LR.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0.0)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='-1')),\n",
    "    ('enocder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "lr_process = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', lr)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.6\n",
      "0.97\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "kfscore_accuracy_overall_LR = cross_val_score(lr_process, X_overall_LR, y_overall_LR, cv=kf, scoring='accuracy')\n",
    "accuracy_overall_LR = round(np.average(kfscore_accuracy_overall_LR) * 100, 2)\n",
    "print(accuracy_overall_LR)\n",
    "\n",
    "accuracy_overall_LR_std = round(np.std(kfscore_accuracy_overall_LR) * 100, 2)\n",
    "\n",
    "table_overall_LR = str(accuracy_overall_LR) + ' [+/-' + str(accuracy_overall_LR_std) + ']'\n",
    "\n",
    "# F1-score\n",
    "kfscore_f1_overall_LR = cross_val_score(lr_process, X_overall_LR, y_overall_LR, cv=kf, scoring='f1')\n",
    "F1_mean_LR = round(np.mean(kfscore_f1_overall_LR), 2)\n",
    "print(F1_mean_LR)\n",
    "\n",
    "F1_std_LR = round(np.std(kfscore_f1_overall_LR), 2)\n",
    "print(F1_std_LR)\n",
    "\n",
    "table_F1_LR = str(F1_mean_LR) + ' [+/-' + str(F1_std_LR) + ']'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### African-American people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.78\n",
      "6.35\n",
      "0.26\n"
     ]
    }
   ],
   "source": [
    "df_black_LR = df_compas.loc[df_compas['race'] == \"African-American\"]\n",
    "\n",
    "X_black_LR = df_black_LR.drop(columns='two_year_recid')\n",
    "y_black_LR = df_black_LR['two_year_recid']\n",
    "\n",
    "numerical_cols = X_black_LR.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X_black_LR.select_dtypes(include=['object']).columns\n",
    "\n",
    "kfscore_accuracy_black_LR = cross_val_score(lr_process, X_black_LR, y_black_LR, cv=kf, scoring='accuracy')\n",
    "\n",
    "accuracy_black_LR = round(np.average(kfscore_accuracy_black_LR) * 100, 2)\n",
    "print(accuracy_black_LR) \n",
    "\n",
    "accuracy_black_LR_std = round(np.std(kfscore_accuracy_black_LR) * 100, 2)\n",
    "\n",
    "table_black_LR = str(accuracy_black_LR) + ' [+/-' + str(accuracy_black_LR_std) + ']'\n",
    "\n",
    "y_pred_black_LR = cross_val_predict(lr_process, X_black_LR, y_black_LR, cv=kf)\n",
    "conf_mat_black_LR = confusion_matrix(y_black_LR, y_pred_black_LR, normalize='true')\n",
    "\n",
    "FP_black_LR = round(conf_mat_black_LR[0,1] * 100, 2)\n",
    "FN_black_LR = round(conf_mat_black_LR[1,0] * 100, 2)\n",
    "\n",
    "print(FP_black_LR)\n",
    "print(FN_black_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caucasian people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.68\n",
      "3.83\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "df_white_LR = df_compas.loc[df_compas['race'] == 'Caucasian']\n",
    "\n",
    "X_white_LR = df_white_LR.drop(columns='two_year_recid')\n",
    "y_white_LR = df_white_LR['two_year_recid']\n",
    "\n",
    "numerical_cols = X_white_LR.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X_white_LR.select_dtypes(include=['object']).columns\n",
    "\n",
    "kfscore_accuracy_white_LR = cross_val_score(lr_process, X_white_LR, y_white_LR, cv=kf, scoring='accuracy')\n",
    "\n",
    "accuracy_white_LR = round(np.average(kfscore_accuracy_white_LR) * 100, 2)\n",
    "print(accuracy_white_LR)\n",
    "\n",
    "accuracy_white_LR_std = round(np.std(kfscore_accuracy_overall_LR) * 100, 2)\n",
    "\n",
    "table_white_LR = str(accuracy_overall_LR) + ' [+/-' + str(accuracy_overall_LR_std) + ']'\n",
    "\n",
    "y_pred_white_LR = cross_val_predict(lr_process, X_white_LR, y_white_LR, cv=kf)\n",
    "conf_mat_white_LR = confusion_matrix(y_white_LR, y_pred_white_LR, normalize='true')\n",
    "\n",
    "FP_white_LR = round(conf_mat_white_LR[0,1] * 100, 2)\n",
    "FN_white_LR = round(conf_mat_white_LR[1,0] * 100, 2)\n",
    "\n",
    "print(FP_white_LR)\n",
    "print(FN_white_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentages within the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of black people: 51.23%\n",
      "Percentage of white people: 34.02%\n",
      "Percentage of female people: 19.34%\n",
      "Percentage of male people: 80.66%\n"
     ]
    }
   ],
   "source": [
    "# black people\n",
    "percentage_black = round(len(df_black_LR7) / len(df_compas) * 100, 2)\n",
    "print(\"Percentage of black people: \" + str(percentage_black) + \"%\")\n",
    "\n",
    "# white people\n",
    "percentage_white = round(len(df_white_LR7) / len(df_compas) * 100, 2)\n",
    "print(\"Percentage of white people: \" + str(percentage_white) + \"%\")\n",
    "\n",
    "# female\n",
    "df_female = df_compas.loc[df_compas['sex'] == \"Female\"]\n",
    "percentage_female = round(len(df_female) / len(df_compas) * 100, 2)\n",
    "print(\"Percentage of female people: \" + str(percentage_female) + \"%\")\n",
    "\n",
    "# male\n",
    "df_male = df_compas.loc[df_compas['sex'] == \"Male\"]\n",
    "percentage_male = round(len(df_male) / len(df_compas) * 100, 2)\n",
    "print(\"Percentage of male people: \" + str(percentage_male) + \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann-Whitney U rank test with LR7 and LR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U = 63.0\n",
      "p = 0.3447042220069576\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "U,p = mannwhitneyu(kfscore_f1_overall_LR7, kfscore_f1_overall_LR2, use_continuity=True, alternative='two-sided', axis=0, method='auto', nan_policy='propagate', keepdims=False)\n",
    "\n",
    "print('U = ' + str(U))\n",
    "print('p = ' + str(p))\n",
    "# Da der p-Wert nicht weniger als 0,05 ist, kann die Nullhypothese nicht abgelehnt werden. \n",
    "# Also gibt es keinen Beweis, dass die F1-Werte in den Gruppen unterschiedlich sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreation of Table 2 in Dressel and Farids (2018) paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ Metric                 â”‚ LR7             â”‚ LR2             â”‚ NL-SVM          â”‚ COMPAS   â”‚ LR8             â”‚ LR              â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ Accuracy (overall)     â”‚ 67.58 [+/-1.62] â”‚ 67.51 [+/-2.14] â”‚ 62.84 [+/-1.4]  â”‚ 65.4     â”‚ 67.74 [+/-1.88] â”‚ 97.6 [+/-0.64]  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Accuracy (black)       â”‚ 66.88 [+/-1.81] â”‚ 67.56 [+/-1.62] â”‚ 62.84 [+/-1.4]  â”‚ 63.8     â”‚ 66.91 [+/-1.87] â”‚ 96.78 [+/-0.61] â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Accuracy (white)       â”‚ 67.58 [+/-1.62] â”‚ 67.97 [+/-2.14] â”‚ 61.74 [+/-0.95] â”‚ 67.0     â”‚ 67.74 [+/-1.88] â”‚ 97.6 [+/-0.64]  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ False Positive (black) â”‚ 37.77           â”‚ 35.71           â”‚ 37.77           â”‚ 44.8     â”‚ 37.77           â”‚ 6.35            â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ False Positive (white) â”‚ 11.29           â”‚ 10.48           â”‚ 11.29           â”‚ 23.5     â”‚ 11.29           â”‚ 3.83            â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ False Negative (black) â”‚ 28.72           â”‚ 28.93           â”‚ 28.72           â”‚ 28.0     â”‚ 28.67           â”‚ 0.26            â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ False Negative (white) â”‚ 65.42           â”‚ 65.32           â”‚ 65.42           â”‚ 47.7     â”‚ 65.42           â”‚ 0.0             â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Mean (F1)              â”‚ 0.6 [+/-0.02]   â”‚ 0.58 [+/-0.03]  â”‚ 0.5 [+/-0.02]   â”‚ -        â”‚ 0.6 [+/-0.02]   â”‚ 0.97 [+/-0.01]  â”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "header = [\"Metric\", \"LR7\", \"LR2\", \"NL-SVM\", \"COMPAS\", \"LR8\", \"LR\"]\n",
    "\n",
    "data = [\n",
    "    [\"Accuracy (overall)\", table_overall_LR7, table_overall_LR2, table_overall_SVM, \"65.4\", table_overall_LR8, table_overall_LR],\n",
    "    [\"Accuracy (black)\", table_black_LR7, table_black_LR2, table_overall_SVM, \"63.8\", table_black_LR8, table_black_LR],\n",
    "    [\"Accuracy (white)\", table_white_LR7, table_white_LR2, table_white_SVM, \"67.0\", table_white_LR8, table_white_LR],\n",
    "    [\"False Positive (black)\", FP_black_LR7, FP_black_LR2, FP_black_SVM, \"44.8\", FP_black_LR8, FP_black_LR],\n",
    "    [\"False Positive (white)\", FP_white_LR7, FP_white_LR2, FP_white_SVM, \"23.5\", FP_white_LR8, FP_white_LR],\n",
    "    [\"False Negative (black)\", FN_black_LR7, FN_black_LR2, FN_black_SVM, \"28.0\", FN_black_LR8, FN_black_LR],\n",
    "    [\"False Negative (white)\", FN_white_LR7, FN_white_LR2, FN_white_SVM, \"47.7\", FN_white_LR8, FN_white_LR],\n",
    "    [\"Mean (F1)\", table_F1_LR7, table_F1_LR2, table_F1_SVM, \"-\", table_F1_LR8, table_F1_LR ],\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers=header, tablefmt=\"fancy_grid\", floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Mitigation to improve Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla XG Boost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6064\n",
      "0.0236\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# the chosen parameters originate from the paper about Tree Boosting Methods\n",
    "\n",
    "# LR7 as comparison\n",
    "table_F1_LR7 = str(round(np.mean(kfscore_f1_overall_LR7), 4)) + ' [+/-' + str(F1_std_LR7) + ']'\n",
    "\n",
    "# Vanilla F1-Score\n",
    "\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(**params)\n",
    "\n",
    "xgb_cv = cross_val_score(xgb, X_overall_LR7, y_overall_LR7, cv=kf, scoring='f1')\n",
    "F1_mean_vanilla = round(np.mean(xgb_cv), 4)\n",
    "print(F1_mean_vanilla)\n",
    "F1_std_vanilla = round(np.std(xgb_cv), 4)\n",
    "print(F1_std_vanilla)\n",
    "table_F1_vanilla = str(F1_mean_vanilla) + ' [+/-' + str(F1_std_vanilla) + ']'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost with RandomizedSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6263\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Random Search\n",
    "param_rs = {\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.02],\n",
    "    'subsample': [1],\n",
    "    'colsample_bytree': [0.4],\n",
    "    'n_estimators': [1000],\n",
    "}\n",
    "\n",
    "xgb_rs = XGBClassifier(**param_rs)\n",
    "\n",
    "# Results RandomizedSearch: {'subsample': 1, 'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.02, 'colsample_bytree': 0.4}\n",
    "# table_F1_tuned_RS = 0.6262595894157256\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_rs, param_distributions=param_rs, scoring='f1', cv=kf)\n",
    "random_search.fit(X_overall_LR7, y_overall_LR7)\n",
    "\n",
    "F1_mean_rs = round(np.mean(random_search.best_score_), 4)\n",
    "print(F1_mean_rs)\n",
    "F1_std_rs = round(np.std(random_search.best_score_), 4)\n",
    "print(F1_std_rs)\n",
    "table_F1_rs = str(F1_mean_rs) + ' [+/-' + str(F1_std_rs) + ']'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6321\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "param_gs = {\n",
    "     'max_depth': [3],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.4],\n",
    "    'colsample_bytree': [1],\n",
    "    'n_estimators': [100],\n",
    "}\n",
    "\n",
    "xgb_gs = XGBClassifier(**param_gs)\n",
    "\n",
    "# Results GridSearch: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.4}\n",
    "# table_F1_tuned_RS = 0.6321110864467466\n",
    "\n",
    "grid_search = GridSearchCV(xgb_gs, param_grid=param_gs, scoring='f1', cv=kf, n_jobs=-1)\n",
    "grid_search.fit(X_overall_LR7, y_overall_LR7)\n",
    "\n",
    "F1_mean_gs = round(np.mean(grid_search.best_score_), 4)\n",
    "print(F1_mean_gs)\n",
    "F1_std_gs = round(np.std(grid_search.best_score_), 4)\n",
    "print(F1_std_gs)\n",
    "table_F1_gs = str(F1_mean_gs) + ' [+/-' + str(F1_std_gs) + ']'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "\n",
    "param_fairlearn_gs = {\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.02],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.4],\n",
    "    'n_estimators': [1000],\n",
    "}\n",
    "\n",
    "xgb_gs = XGBClassifier(**param_fairlearn_gs)\n",
    "\n",
    "cr = CorrelationRemover(sensitive_feature_ids=['race'])\n",
    "cr.fit(X_overall_LR8)\n",
    "X_overall_fairlearn = cr.transform(X_overall_LR8)\n",
    "\n",
    "fairlearn_gs = GridSearchCV(xgb_gs, param_grid=param_fairlearn_gs, scoring='f1', cv=kf, n_jobs=-1)\n",
    "fairlearn_gs.fit(X_overall_fairlearn, y_overall_LR7)\n",
    "# {'colsample_bytree': 0.4, 'learning_rate': 0.02, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.8}\n",
    "# 0.6240178246633066\n",
    "\n",
    "F1_mean_fairlearn_gs = round(np.mean(fairlearn_gs.best_score_), 4)\n",
    "print(F1_mean_fairlearn_gs)\n",
    "F1_std_fairlearn_gs = round(np.std(fairlearn_gs.best_score_), 4)\n",
    "print(F1_std_fairlearn_gs)\n",
    "table_F1_fairlearn_gs = str(F1_mean_fairlearn_gs) + ' [+/-' + str(F1_std_fairlearn_gs) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fairlearn\\postprocessing\\_interpolated_thresholder.py:166: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.02427631 0.89650624 0.02427631 ... 0.02427631 0.02427631 0.02427631]' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  positive_probs[sensitive_feature_vector == a] = interpolated_predictions[\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "param_gs_threshold_opt = {\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.02],\n",
    "    'subsample': [1],\n",
    "    'colsample_bytree': [0.6],\n",
    "    'n_estimators': [5000],\n",
    "}\n",
    "\n",
    "xgb_gs = XGBClassifier(**param_gs_threshold_opt)\n",
    "\n",
    "grid_search = GridSearchCV(xgb_gs, param_grid=param_gs_threshold_opt, scoring='f1', cv=kf, n_jobs=-1)\n",
    "grid_search.fit(X_overall_LR8, y_overall_LR7)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# {'colsample_bytree': 0.6, 'learning_rate': 0.02, 'max_depth': 3, 'n_estimators': 5000, 'subsample': 1}\n",
    "# 0.6522\n",
    "\n",
    "threshold_optimizer = ThresholdOptimizer(\n",
    "    estimator=best_model,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\",\n",
    "    objective='accuracy_score',\n",
    ")\n",
    "\n",
    "threshold_optimizer.fit(X_overall_LR8, y_overall_LR7, sensitive_features=X_overall_LR8['race'])\n",
    "\n",
    "y_pred = threshold_optimizer.predict(X_overall_LR8, sensitive_features=X_overall_LR8['race'], random_state=18)\n",
    "\n",
    "table_F1_fairlearn_threshold_opt = f1_score(y_overall_LR7, y_pred)\n",
    "table_F1_fairlearn_threshold_opt = round(table_F1_fairlearn_threshold_opt, 4)\n",
    "print(table_F1_fairlearn_threshold_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI Fairness 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 884. MiB for an array with shape (926983200,) and data type int8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 26\u001b[0m\n\u001b[0;32m     17\u001b[0m optim_options \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistortion_fun\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_distortion_compas,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m }\n\u001b[0;32m     24\u001b[0m OP \u001b[38;5;241m=\u001b[39m OptimPreproc(OptTools, optim_options)\n\u001b[1;32m---> 26\u001b[0m dataset_transf \u001b[38;5;241m=\u001b[39m \u001b[43mOP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m X_overall_LR8_transf \u001b[38;5;241m=\u001b[39m dataset_transf\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[0;32m     29\u001b[0m y_overall_LR7_transf \u001b[38;5;241m=\u001b[39m dataset_transf\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\transformer.py:27\u001b[0m, in \u001b[0;36maddmetadata.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 27\u001b[0m     new_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_dataset, Dataset):\n\u001b[0;32m     29\u001b[0m         new_dataset\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m new_dataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\preprocessing\\optim_preproc.py:222\u001b[0m, in \u001b[0;36mOptimPreproc.fit_transform\u001b[1;34m(self, dataset, sep, transform_Y)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m, transform_Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perfom :meth:`fit` and :meth:`transform` sequentially.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(dataset, sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m    223\u001b[0m                                                 transform_Y\u001b[38;5;241m=\u001b[39mtransform_Y)\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\transformer.py:27\u001b[0m, in \u001b[0;36maddmetadata.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 27\u001b[0m     new_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_dataset, Dataset):\n\u001b[0;32m     29\u001b[0m         new_dataset\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m new_dataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\preprocessing\\optim_preproc.py:110\u001b[0m, in \u001b[0;36mOptimPreproc.fit\u001b[1;34m(self, dataset, sep)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOpT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer(df\u001b[38;5;241m=\u001b[39mdf, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Set features\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprotected_attribute_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_feature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY_feature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Set Distortion\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOpT\u001b[38;5;241m.\u001b[39mset_distortion(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistortion_fun\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    116\u001b[0m                         clist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclist\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\algorithms\\preprocessing\\optim_preproc_helpers\\opt_tools.py:178\u001b[0m, in \u001b[0;36mOptTools.set_features\u001b[1;34m(self, D, X, Y)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mXY_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_features\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_features\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mXY_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_values\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_values\n\u001b[1;32m--> 178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mXY_index \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_product\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXY_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXY_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Initialize mapping dataframe\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdfP \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDXY_index),\n\u001b[0;32m    183\u001b[0m                                   \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mXY_index))),\n\u001b[0;32m    184\u001b[0m                         index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDXY_index, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mXY_index)\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:682\u001b[0m, in \u001b[0;36mMultiIndex.from_product\u001b[1;34m(cls, iterables, sortorder, names)\u001b[0m\n\u001b[0;32m    679\u001b[0m     names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(it, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# codes are all ndarrays, so cartesian_product is lossless\u001b[39;00m\n\u001b[1;32m--> 682\u001b[0m codes \u001b[38;5;241m=\u001b[39m \u001b[43mcartesian_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(levels, codes, sortorder\u001b[38;5;241m=\u001b[39msortorder, names\u001b[38;5;241m=\u001b[39mnames)\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\util.py:65\u001b[0m, in \u001b[0;36mcartesian_product\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     59\u001b[0m     b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(cumprodX)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# error: Argument of type \"int_\" cannot be assigned to parameter \"num\" of\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# type \"int\" in function \"tile_compat\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     64\u001b[0m     tile_compat(\n\u001b[1;32m---> 65\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     66\u001b[0m         np\u001b[38;5;241m.\u001b[39mprod(a[i]),  \u001b[38;5;66;03m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     )\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X)\n\u001b[0;32m     69\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:466\u001b[0m, in \u001b[0;36mrepeat\u001b[1;34m(a, repeats, axis)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_repeat_dispatcher)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat\u001b[39m(a, repeats, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m    Repeat each element of an array after themselves\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrepeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 884. MiB for an array with shape (926983200,) and data type int8"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.preprocessing import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions import get_distortion_compas\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data = X_overall_LR8.copy()\n",
    "data['label'] = y_overall_LR7\n",
    "data['race'] = X_overall_LR8['race']\n",
    "\n",
    "# {0: 'African-American', 1: 'Asian', 2: 'Caucasian', 3: 'Hispanic', 4: 'Native American', 5: 'Other'}\n",
    "privileged_groups = [{'race': 2}]\n",
    "unprivileged_groups =  [{'race': 0}, {'race': 1}, {'race': 3}, {'race': 4}, {'race': 5}]\n",
    "\n",
    "dataset = BinaryLabelDataset(df=data, label_names=['label'], protected_attribute_names=['race'])\n",
    "\n",
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_compas,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "\n",
    "}\n",
    "OP = OptimPreproc(OptTools, optim_options)\n",
    "\n",
    "dataset_transf = OP.fit_transform(dataset)\n",
    "\n",
    "X_overall_LR8_transf = dataset_transf.features\n",
    "y_overall_LR7_transf = dataset_transf.labels.ravel()\n",
    "\n",
    "param_gs_threshold_opt = {\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.02],\n",
    "    'subsample': [1],\n",
    "    'colsample_bytree': [0.6],\n",
    "    'n_estimators': [5000],\n",
    "}\n",
    "\n",
    "xgb_gs = XGBClassifier(**param_gs_threshold_opt)\n",
    "\n",
    "grid_search = GridSearchCV(xgb_gs, param_grid=param_gs_threshold_opt, scoring='f1', cv=kf, n_jobs=-1)\n",
    "grid_search.fit(X_overall_LR8_transf, y_overall_LR7_transf)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# {'colsample_bytree': 0.6, 'learning_rate': 0.02, 'max_depth': 3, 'n_estimators': 5000, 'subsample': 1}\n",
    "# 0.6522\n",
    "\n",
    "threshold_optimizer = ThresholdOptimizer(\n",
    "    estimator=best_model,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\",\n",
    "    objective='accuracy_score',\n",
    ")\n",
    "\n",
    "threshold_optimizer.fit(X_overall_LR8_transf, y_overall_LR7_transf, sensitive_features=X_overall_LR8['race'])\n",
    "\n",
    "y_pred = threshold_optimizer.predict(X_overall_LR8_transf, sensitive_features=X_overall_LR8['race'], random_state=18)\n",
    "\n",
    "table_F1_fairlearn_threshold_opt = f1_score(y_overall_LR7_transf, y_pred)\n",
    "table_F1_fairlearn_threshold_opt = round(table_F1_fairlearn_threshold_opt, 4)\n",
    "print(table_F1_fairlearn_threshold_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ LR7              â”‚ Vanilla            â”‚ RandomizedSearch   â”‚ GridSearch      â”‚   Fairlearn â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0.5994 [+/-0.02] â”‚ 0.6064 [+/-0.0236] â”‚ 0.6263 [+/-0.0]    â”‚ 0.6321 [+/-0.0] â”‚      0.6565 â”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "header = [\"LR7\", \"Vanilla\",  \"RandomizedSearch\", \"GridSearch\", \"Fairlearn\", \"AI Fairness 360\"]\n",
    "\n",
    "data = [\n",
    "    [table_F1_LR7, table_F1_vanilla,  table_F1_rs, table_F1_gs, table_F1_fairlearn_threshold_opt],\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers=header, tablefmt=\"fancy_grid\", floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quellen:\n",
    "\n",
    "RegenerativeToday. (18.05.2022). Step by Step Tutorial on Logistic Regression in Python | sklearn |Jupyter Notebook [Video]. Youtube. https://www.youtube.com/watch?v=bSXIbCZNBw0\n",
    "\n",
    "Dressel, A. & Farid, H. (2018). The accuracy, fairness, and limits of predicting recidivism. Science Advances, 4 (1), eaao5580. https://doi.org/10.1126/sciadv.aao5580\n",
    "\n",
    "Ryan Nolan Data. (28.08.2023). A Comprehensive Guide to Cross-Validation with Scikit-Learn and Python [Video]. Youtube. https://www.youtube.com/watch?v=glLNo1ZnmPA&list=PLcQVY5V2UY4LNmObS0gqNVyNdVfXnHwu8&index=14\n",
    "\n",
    "Scikit-Learn. (n.d.). User Guide. https://scikit-learn.org/stable/user_guide.html\n",
    "\n",
    "Scikit-Learn. (n.d.). API Reference. https://scikit-learn.org/stable/api/index.html\n",
    "\n",
    "Geeks for Geeks. (2022). How to make a table in Python?. https://www.geeksforgeeks.org/how-to-make-a-table-in-python/\n",
    "\n",
    "Stackoverflow. (2016). Python's tabulate number of decimal. https://stackoverflow.com/questions/37079957/pythons-tabulate-number-of-decimal\n",
    "\n",
    "Stackoverflow. (2018). How can I standardize only numeric variables in an sklearn pipeline?. https://stackoverflow.com/questions/48673402/how-can-i-standardize-only-numeric-variables-in-an-sklearn-pipeline\n",
    "\n",
    "Velarde, G., Weichert, M., Deshmunkh, A., Deshmane, S., Sudhir, A., Sharma, K. & Joshi, V. (2024). Tree boosting methods for balanced and imbalanced classification and their robustness over time in risk assessment. Intelligent Systems with Applications. 22, 200354. https://doi.org/10.1016/j.iswa.2024.200354\n",
    "\n",
    "Weerts, H. (19.06.2024). An Introduction to Responsible Machine Learning. GitHub. https://hildeweerts.github.io/responsiblemachinelearning/index.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
